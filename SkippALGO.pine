// This Pine ScriptÂ® code is subject to the terms of the Mozilla Public License 2.0 at https://mozilla.org/MPL/2.0/
// Â© preuss_steffen

//@version=6
// SkippALGO â€” Deep Upgrade (Phases 1-4)
// Implements advanced calibration and forecasting logic:
// Phase 1: Timeframe-specific Target Profiles (Fast/Mid/Slow)
// Phase 2: 2D Binning (Algorithm Score + Volatility Regime)
// Phase 3: Ensemble Scoring (Trend + Pullback + Volatility Bias)
// Phase 4: Online Calibration (Platt Scaling via SGD + Brier/LogLoss tracking)

indicator("SkippALGO â€” Deep Upgrade v6.1", overlay=true, max_labels_count=500, max_lines_count=500)

//====================
// Inputs â€” Core / Engine
//====================
config = input.string("V2 Alpha", "Configuration", options=["Standard", "Pro", "V2 Essential", "V2 Proficient", "V2 Alpha"])

// Signal engine
engine       = input.string("Trend+Pullback", "Signal engine", options=["Trend+Pullback", "Loose", "TRIG (legacy)"])
enableShorts = input.bool(false, "Enable shorts (SHORT can open short)")
cooldownBars = input.int(6, "Cooldown bars", minval=0)
minTrust     = input.float(0.55, "Min confidence (0..1)", minval=0.0, maxval=1.0, step=0.01)

// MTF use (filter / regime)
useMtfConfirm = input.bool(true, "MTF confirmation")
mtfSet        = input.string("Auto", "MTF set", options=["Auto", "Short", "Medium", "Long"])
tfShort1      = input.timeframe("5", "Short TF 1")
tfShort2      = input.timeframe("15", "Short TF 2")
tfShort3      = input.timeframe("30", "Short TF 3")
tfMedium1     = input.timeframe("60", "Medium TF 1")
tfMedium2     = input.timeframe("240", "Medium TF 2")
tfMedium3     = input.timeframe("D", "Medium TF 3")
tfLong1       = input.timeframe("D", "Long TF 1")
tfLong2       = input.timeframe("5D", "Long TF 2")
tfLong3       = input.timeframe("10D", "Long TF 3")

// Forecast horizons (table rows)
tfF1 = input.timeframe("1",   "Forecast 1")   // 1M
tfF2 = input.timeframe("5",   "Forecast 2")   // 5M
tfF3 = input.timeframe("15",  "Forecast 3")   // 15M
tfF4 = input.timeframe("30",  "Forecast 4")   // 30M
tfF5 = input.timeframe("60",  "Forecast 5")   // 1H
tfF6 = input.timeframe("240", "Forecast 6")   // 4H
tfF7 = input.timeframe("D",   "Forecast 7")   // 1D

// Trust-score weighting
trustWAccuracy  = input.float(0.40, "Trust weight: accuracy", minval=0.0, step=0.05)
trustWRegime    = input.float(0.30, "Trust weight: regime", minval=0.0, step=0.05)
trustWGuardrail = input.float(0.20, "Trust weight: guardrails", minval=0.0, step=0.05)

//====================
// Constants â€” Avoid Magic Numbers
//====================
// Volatility regime thresholds
VOL_THRESH_HIGH = 0.66    // High volatility threshold
VOL_THRESH_LOW  = 0.33    // Low volatility threshold

// Statistical constants
Z_95            = 1.96    // Z-score for 95% confidence interval
PROB_EPS        = 0.0001  // Epsilon for probability clamping to avoid log(0)

// Rolling buffer recalculation interval (prevent FP drift)
ROLL_RECALC_INTERVAL = 500
trustWData      = input.float(0.10, "Trust weight: data quality", minval=0.0, step=0.05)
trustWMacro     = input.float(0.10, "Trust weight: macro context", minval=0.0, step=0.05)

penaltyGuardrail  = input.float(0.20, "Penalty per guardrail flag", minval=0.0, step=0.05)
penaltyRegimeHigh = input.float(0.20, "Penalty: high-vol regime", minval=0.0, step=0.05)
penaltyRegimeMed  = input.float(0.10, "Penalty: medium-vol regime", minval=0.0, step=0.05)

volRankMed  = input.float(0.60, "Regime threshold: vol medium", minval=0.0, maxval=1.0, step=0.05)
volRankHigh = input.float(0.80, "Regime threshold: vol high", minval=0.0, maxval=1.0, step=0.05)

gapShockPct   = input.float(0.0125, "Guardrail: gap shock %", minval=0.0, step=0.0025)
rangeShockPct = input.float(0.05,   "Guardrail: range shock %", minval=0.0, step=0.01)

// Macro context
macroPctLen         = input.int(252, "Macro pct-rank lookback", minval=20)
macroPctLenIntraday = input.int(200, "Macro pct-rank intraday fallback", minval=20)
macroGateMode       = input.string("Trust", "Macro context mode", options=["Off", "Trust", "Hard Gate"])
macroLongPctThreshold  = input.float(0.35, "Macro LONG threshold (pct rank)",  minval=0.0, maxval=1.0, step=0.05)
macroShortPctThreshold = input.float(0.65, "Macro SHORT threshold (pct rank)", minval=0.0, maxval=1.0, step=0.05)

// Drawdown-aware haircut
ddLookback     = input.int(120, "Drawdown lookback", minval=20)
ddMild         = input.float(0.10, "Drawdown mild (abs)", minval=0.05, step=0.05)
ddSevere       = input.float(0.30, "Drawdown severe (abs)", minval=0.10, step=0.05)
ddTrustPenalty = input.float(0.20, "Drawdown trust penalty", minval=0.0, maxval=1.0, step=0.05)
ddHardGate     = input.float(0.45, "Drawdown hard gate (abs)", minval=0.0, maxval=0.9, step=0.05)

// Core lengths (trend)
emaFastLen = input.int(21, "EMA fast", minval=1)
emaSlowLen = input.int(55, "EMA slow", minval=1)
atrLen     = input.int(14, "ATR length", minval=1)
volRankLen = input.int(100,"Volatility rank lookback", minval=20)

// Confidence momentum: Adaptive RSI + hysteresis (Trend-Continuation friendly)
useAdaptiveRsi = input.bool(true, "Adaptive RSI length by TF (confidence)")
rsiLenFastTF   = input.int(7,  "RSI len (<=5m)", minval=2)
rsiLenMidTF    = input.int(9,  "RSI len (<=1h)", minval=2)
rsiLenSlowTF   = input.int(14, "RSI len (>1h)",  minval=2)

rsiLongOn   = input.float(55.0, "RSI long ON",  minval=0.0, maxval=100.0, step=0.5)
rsiLongOff  = input.float(50.0, "RSI long OFF", minval=0.0, maxval=100.0, step=0.5)
rsiShortOn  = input.float(45.0, "RSI short ON",  minval=0.0, maxval=100.0, step=0.5)
rsiShortOff = input.float(50.0, "RSI short OFF", minval=0.0, maxval=100.0, step=0.5)

// Outlook/MTF RSI length (stable)
rsiStateLen = input.int(14, "State/MTF RSI length", minval=2)

// Connors RSI (3,2,100) used as confidence factor
useCrsiFactor      = input.bool(true, "CRSI factor on confidence")
crsiRsiLen         = input.int(3,   "CRSI: RSI len", minval=2)
crsiStreakRsiLen   = input.int(2,   "CRSI: Streak RSI len", minval=2)
crsiRankLen        = input.int(100, "CRSI: Rank len", minval=20)

crsiLongGoodLo     = input.float(15.0, "CRSI LONG good (lo)", minval=0.0, maxval=100.0, step=1.0)
crsiLongGoodHi     = input.float(55.0, "CRSI LONG good (hi)", minval=0.0, maxval=100.0, step=1.0)
crsiLongGoodMult   = input.float(1.10, "CRSI LONG good mult", minval=0.50, maxval=1.50, step=0.01)
crsiLongOver       = input.float(80.0, "CRSI LONG over", minval=0.0, maxval=100.0, step=1.0)
crsiLongOverMult   = input.float(0.85, "CRSI LONG over mult", minval=0.50, maxval=1.50, step=0.01)
crsiLongPanic      = input.float(10.0, "CRSI LONG panic", minval=0.0, maxval=100.0, step=1.0)
crsiLongPanicMult  = input.float(0.90, "CRSI LONG panic mult", minval=0.50, maxval=1.50, step=0.01)

crsiShortGoodLo      = input.float(45.0, "CRSI SHORT good (lo)", minval=0.0, maxval=100.0, step=1.0)
crsiShortGoodHi      = input.float(85.0, "CRSI SHORT good (hi)", minval=0.0, maxval=100.0, step=1.0)
crsiShortGoodMult    = input.float(1.10, "CRSI SHORT good mult", minval=0.50, maxval=1.50, step=0.01)
crsiShortExhaust     = input.float(20.0, "CRSI SHORT exhaust", minval=0.0, maxval=100.0, step=1.0)
crsiShortExhaustMult = input.float(0.85, "CRSI SHORT exhaust mult", minval=0.50, maxval=1.50, step=0.01)
crsiShortOver        = input.float(90.0, "CRSI SHORT over", minval=0.0, maxval=100.0, step=1.0)
crsiShortOverMult    = input.float(0.90, "CRSI SHORT over mult", minval=0.50, maxval=1.50, step=0.01)

// Zones
showZones  = input.bool(true, "Show zones")
zoneAnchor = input.string("EMA Slow", "Zone anchor", options=["Entry", "EMA Fast", "EMA Slow", "VWAP", "MA200"])
zoneMode   = input.string("Pullback", "Zone mode", options=["Pullback", "Symmetric"])
zoneNeutralMult      = input.float(0.8, "Neutral zone ATR mult", minval=0.1, step=0.1)
zoneAggressiveMult1  = input.float(1.6, "Aggressive zone ATR mult 1", minval=0.2, step=0.1)
zoneAggressiveMult2  = input.float(2.4, "Aggressive zone ATR mult 2", minval=0.4, step=0.1)

// Visual controls
showEntryLabels  = input.bool(true, "Show labels (BUY / EXIT / SHORT)")
showSetMarkers   = input.bool(true, "Show SET markers")
showTable        = input.bool(true, "Show Outlook/Forecast table")

// Avoid entries right before close
useRthCloseFilter = input.bool(true, "Avoid last N minutes before RTH close")
rthCloseHour      = input.int(16, "RTH close hour (exchange tz)", minval=0, maxval=23)
rthCloseMinute    = input.int(0,  "RTH close minute", minval=0, maxval=59)
avoidCloseMins    = input.int(10, "Avoid last N minutes", minval=0, maxval=120)

//====================
// Inputs â€” UT Bot Verification Overlay
//====================
grpUt       = "UT Bot Verification"
utShow      = input.bool(false, "Show UT Bot Overlay", group=grpUt)
utKey       = input.float(1.0, "Key Value", group=grpUt) 
utAtrPeriod = input.int(10, "ATR Period", group=grpUt) 
utUseHA     = input.bool(false, "Use Heikin Ashi", group=grpUt) 

//====================
// Inputs â€” Forecast Calibration Enhancements
//====================
enableForecast = input.bool(true, "Enable Forecast calibration (probabilities)")

// Forecast value display
fcDisplay = input.string("Up% (N)", "Forecast value display", options=["Up% (N)", "Edge pp (N)"])

// --- Phase 1: Separate Targets per Timeframe Group ---
grp_fast = "Target Profile 1: Fast (1m, 5m)"
fcTargetF = input.string("KBarATR", "Target", options=["NextBar", "KBarReturn", "KBarATR", "PathTPvsSL"], group=grp_fast)
kBarsF    = input.int(3, "k bars", minval=1, maxval=20, group=grp_fast)
atrThrF   = input.float(0.25, "ATR Thr", step=0.05, group=grp_fast)
pathHF    = input.int(6, "Path H", minval=1, maxval=50, group=grp_fast)
tpATRF    = input.float(0.50, "Path TP", step=0.05, group=grp_fast)
slATRF    = input.float(0.30, "Path SL", step=0.05, group=grp_fast)

grp_mid = "Target Profile 2: Mid (15m, 30m, 1h)"
fcTargetM = input.string("PathTPvsSL", "Target", options=["NextBar", "KBarReturn", "KBarATR", "PathTPvsSL"], group=grp_mid)
kBarsM    = input.int(5, "k bars", minval=1, maxval=20, group=grp_mid)
atrThrM   = input.float(0.50, "ATR Thr", step=0.05, group=grp_mid)
pathHM    = input.int(8, "Path H", minval=1, maxval=50, group=grp_mid)
tpATRM    = input.float(0.80, "Path TP", step=0.05, group=grp_mid)
slATRM    = input.float(0.50, "Path SL", step=0.05, group=grp_mid)

grp_slow = "Target Profile 3: Slow (4h, 1D, ...)"
fcTargetS = input.string("PathTPvsSL", "Target", options=["NextBar", "KBarReturn", "KBarATR", "PathTPvsSL"], group=grp_slow)
kBarsS    = input.int(10, "k bars", minval=1, maxval=50, group=grp_slow)
atrThrS   = input.float(1.00, "ATR Thr", step=0.05, group=grp_slow)
pathHS    = input.int(12, "Path H", minval=1, maxval=100, group=grp_slow)
tpATRS    = input.float(1.20, "Path TP", step=0.05, group=grp_slow)
slATRS    = input.float(0.80, "Path SL", step=0.05, group=grp_slow)

// Global Policies
noHitPolicy   = input.string("Ignore", "No-hit policy (PathTPvsSL)", options=["Ignore", "Neutral", "Loss"])
pathTiePolicy = input.string("Loss", "Tie policy if TP & SL hit same bar", options=["Loss", "Neutral", "Win"])
atrTargetLen  = input.int(14, "ATR len (forecast targets)", minval=2)

// --- Phase 2: Calibration Dimensions ---
predBinsN     = input.int(3, "Pred bins (N) state", minval=2, maxval=9)
dim2Bins      = 3 // Fixed: Low, Med, High Volatility Regime

predBins1     = input.int(2, "Pred bins (1) reactive", minval=2, maxval=3)

alphaN  = input.float(1.0, "Smoothing alpha (N)", minval=0.1, step=0.1)
alpha1  = input.float(0.8, "Smoothing alpha (1)", minval=0.1, step=0.1)
kShrink = input.int(5, "Base Rate Shrinkage k", minval=0, maxval=1000)

calMinSamples = input.int(40, "Min samples per bin (activate)", minval=5, maxval=1000)

predUpThr = input.float(0.55, "Pred up threshold", minval=0.50, maxval=0.80, step=0.01)
predDnThr = input.float(0.45, "Pred down threshold", minval=0.20, maxval=0.50, step=0.01)

// --- Phase 3: Ensemble Weights ---
grp_ens = "Phase 3: Ensemble Weights"
wState    = input.float(1.0, "Weight: State (Outlook)", step=0.1, group=grp_ens)
wPullback = input.float(0.5, "Weight: Pullback Depth", step=0.1, group=grp_ens)
wRegime   = input.float(0.3, "Weight: Vol Regime", step=0.1, group=grp_ens)

// --- Phase 4: Platt Scaling (Online Calibration) ---
usePlatt = input.bool(true, "Phase 4: Use Platt Scaling (SGD)", group="Calibration Tuning")
lrPlatt  = input.float(0.002, "Learning Rate", step=0.001, group="Calibration Tuning")

// Per-horizon reset control
resetWhich = input.string("None", "Reset calibration scope", options=["None","All","F1","F2","F3","F4","F5","F6","F7"])
resetNow   = input.bool(false, "Reset selected calibration NOW")

//====================
// Inputs â€” Forecast Filtering (Accuracy-based)
//====================
useRelFilter = input.bool(false, "Filter entries by Forecast Accuracy")
maxBrier     = input.float(0.25, "Max Brier Score (lower=better)", minval=0.01, step=0.01)
relFilterTF  = input.string("F6", "Filter Horizon", options=["F1","F2","F3","F4","F5","F6","F7"], tooltip="Check accuracy of this forecast timeframe")
relFilterModel = input.string("N", "Filter Model", options=["N", "1"], tooltip="N=Multi-factor, 1=Single-factor")

//====================
// Inputs â€” Evaluation (live scoring)
//====================
showEvalSection = input.bool(true, "Show Evaluation rows (Brier/LogLoss/ECE/Drift)")
evalWhichHead   = input.string("N", "Evaluate head", options=["N","1"])  // N=stable bins, 1=reactive bins

evalMode        = input.string("History+Live", "Evaluation mode", options=["History+Live","LiveOnly"])

evalRollScore   = input.int(200, "Eval rolling window: score (events)", minval=20, maxval=2000)
evalRollShort   = input.int(50,  "Eval drift short window (events)", minval=10, maxval=500)
evalRollLong    = input.int(300, "Eval drift long window (events)", minval=30, maxval=3000)

evalBuckets     = input.int(5, "Eval buckets (ECE)", minval=3, maxval=5)
evalMinEvents   = input.int(30, "Eval min events to display", minval=5, maxval=500)

driftWarnPP     = input.float(8.0, "Drift warn threshold (pp)", minval=1.0, maxval=50.0, step=0.5)

//====================
// Inputs â€” Calibration Diagnostics (Debug Panel)
//====================
grp_diag = "ðŸ”§ Calibration Diagnostics"
showDiagPanel   = input.bool(false, "Show Calibration Debug Panel", group=grp_diag, tooltip="Displays Platt params, convergence, bin samples")
diagHorizon     = input.string("F1", "Diagnostic Horizon", options=["F1","F2","F3","F4","F5","F6","F7"], group=grp_diag)
diagModel       = input.string("N", "Diagnostic Model", options=["N","1"], group=grp_diag, tooltip="N=Multi-factor, 1=Single-factor")

//====================
// Calibration storage â€” per horizon TF (Global State)
//====================

// UDT to hold all state arrays for a single timeframe horizon
type TfState
    int[]   cntN
    int[]   upN
    int[]   cnt1
    int[]   up1
    // Queues
    int[]   qBinN
    int[]   qBin1
    float[] qEntry
    float[] qAtr
    float[] qMaxH
    float[] qMinL
    int[]   qAge
    float[] qProbN
    float[] qProb1
    float[] qLogitN
    float[] qLogit1
    float[] qPredN
    float[] qPred1
    // Stats
    float[] brierStatsN
    float[] brierStats1
    float[] llStatsN
    float[] llStats1
    float[] plattN
    float[] platt1
    // Evaluation N
    float[] evBrierN
    float[] evSumBrierN
    float[] evLogN
    float[] evSumLogN
    float[] evYS_N
    float[] evSumYS_N
    float[] evYL_N
    float[] evSumYL_N
    int[]   evCalCntN
    float[] evCalSumPN
    float[] evCalSumYN
    int[]   evCalBBufN
    float[] evCalPBufN
    float[] evCalYBufN
    // Evaluation 1
    float[] evBrier1
    float[] evSumBrier1
    float[] evLog1
    float[] evSumLog1
    float[] evYS_1
    float[] evSumYS_1
    float[] evYL_1
    float[] evSumYL_1
    int[]   evCalCnt1
    float[] evCalSumP1
    float[] evCalSumY1
    int[]   evCalBBuf1
    float[] evCalPBuf1
    float[] evCalYBuf1

// Helper to initialize TfState
f_init_tf_state(int nBinsN, int nBins1, int dim2, int evBuckets) =>
    TfState.new(
      array.new_int(nBinsN * dim2, 0), array.new_int(nBinsN * dim2, 0),
      array.new_int(nBins1 * dim2, 0), array.new_int(nBins1 * dim2, 0),
      array.new_int(), array.new_int(),
      array.new_float(), array.new_float(), array.new_float(), array.new_float(), array.new_int(),
      array.new_float(), array.new_float(), array.new_float(), array.new_float(), array.new_float(), array.new_float(),
      array.new_float(2, 0.0), array.new_float(2, 0.0),
      array.new_float(2, 0.0), array.new_float(2, 0.0),
      array.from(1.0, 0.0), array.from(1.0, 0.0),
      // Eval N
      array.new_float(), array.new_float(1, 0.0), array.new_float(), array.new_float(1, 0.0),
      array.new_float(), array.new_float(1, 0.0), array.new_float(), array.new_float(1, 0.0),
      array.new_int(evBuckets, 0), array.new_float(evBuckets, 0.0), array.new_float(evBuckets, 0.0),
      array.new_int(), array.new_float(), array.new_float(),
      // Eval 1
      array.new_float(), array.new_float(1, 0.0), array.new_float(), array.new_float(1, 0.0),
      array.new_float(), array.new_float(1, 0.0), array.new_float(), array.new_float(1, 0.0),
      array.new_int(evBuckets, 0), array.new_float(evBuckets, 0.0), array.new_float(evBuckets, 0.0),
      array.new_int(), array.new_float(), array.new_float()
    )

var TfState tf1State = f_init_tf_state(predBinsN, predBins1, dim2Bins, evalBuckets)
var TfState tf2State = f_init_tf_state(predBinsN, predBins1, dim2Bins, evalBuckets)
var TfState tf3State = f_init_tf_state(predBinsN, predBins1, dim2Bins, evalBuckets)
var TfState tf4State = f_init_tf_state(predBinsN, predBins1, dim2Bins, evalBuckets)
var TfState tf5State = f_init_tf_state(predBinsN, predBins1, dim2Bins, evalBuckets)
var TfState tf6State = f_init_tf_state(predBinsN, predBins1, dim2Bins, evalBuckets)
var TfState tf7State = f_init_tf_state(predBinsN, predBins1, dim2Bins, evalBuckets)

//====================
// Evaluation storage â€” per horizon (Head N and Head 1)
//====================
// F1 â€” Head N
// (Globals removed, now in TfState)

//====================
// Table colors (navy + soft-blue frame)
//====================
tblBg      = color.new(color.rgb(12, 20, 35), 0)
tblHeader  = color.new(color.rgb(12, 20, 35), 0)
tblCell    = color.new(color.rgb(12, 20, 35), 0)
tblFrame   = color.new(color.rgb(100, 130, 200), 50)
tblText    = color.white
tblTextDim = color.new(color.white, 25)
tblTfColor = color.new(color.rgb(220, 220, 255), 0)

//====================
// Helpers
//====================
// --- Sum int array (total resolved samples across all bins)
f_sum_int_array(a) =>
    int s = 0
    for i = 0 to array.size(a) - 1
        s += array.get(a, i)
    s

// --- Human name for "chance" depending on forecast target
f_chance_word() =>
    anyWin = fcTargetF == "PathTPvsSL" or fcTargetM == "PathTPvsSL" or fcTargetS == "PathTPvsSL"
    anyWin ? "Win" : "Up"

// --- 95% CI half-width (approx) for Bernoulli p with n samples
f_ci95_halfwidth(p, n) =>
    n <= 0 ? na : Z_95 * math.sqrt(p * (1.0 - p) / n)

// --- Reliability label based on CI half-width
f_rel_label(p, nBin, total, canCal) =>
    string lbl = "off"
    if not canCal
        lbl := "off"
    else if total <= 0
        lbl := "n/a"
    else if nBin < calMinSamples
        lbl := "warmup"
    else
        hw = f_ci95_halfwidth(p, nBin)
        lbl := na(hw) ? "warmup" : hw <= 0.05 ? "strong" : hw <= 0.10 ? "ok" : "weak"
    lbl

// --- Color for reliability label (subtle; does NOT conflict with up/down coloring)
f_rel_color(p, nBin, total, canCal) =>
    if not canCal
        color.new(color.white, 70)
    else if total <= 0
        color.new(color.white, 60)
    else if nBin < calMinSamples
        color.new(color.white, 60)
    else
        hw = f_ci95_halfwidth(p, nBin)
        na(hw) ? color.new(color.white, 60) : hw <= 0.05 ? color.lime : hw <= 0.10 ? color.yellow : tblTextDim

//====================
// Forecast display helpers (human formatting)
//====================

// Map a TF into your "Fast/Mid/Slow" profiles.
f_profile(tf) =>
    s = timeframe.in_seconds(tf)
    // Fast: <= 15m, Mid: <= 4h, Slow: > 4h
    not na(s) and s <= timeframe.in_seconds("900")  ? "Fast" :
    not na(s) and s <= timeframe.in_seconds("14400") ? "Mid"  : "Slow"

// Pick which target is active for that TF profile.
f_target_for_tf(tf) =>
    prof = f_profile(tf)
    prof == "Fast" ? fcTargetF :
    prof == "Mid"  ? fcTargetM  : fcTargetS

// Short, human label for the target (what "Win" means on that row)
f_target_label(tf) =>
    t = f_target_for_tf(tf)
    t == "NextBar"    ? "Next-up" :
    t == "KBarReturn" ? "Up-close" :
    t == "KBarATR"    ? "ATR-hit"  :
    t == "PathTPvsSL" ? "TP-first" : "Win"

// Uncertainty band in percentage points using a binomial approx (â‰ˆ95% band).
f_unc_pp(p, n) =>
    n <= 0 ? na : Z_95 * math.sqrt(math.max(p * (1.0 - p), 0.0) / n) * 100.0

// Sample-strength label derived from CURRENT BIN sample size (nBin).
f_strength_label_fc(nBin) =>
    nBin < calMinSamples ? "weak" :
    nBin < calMinSamples * 4 ? "ok" : "strong"

// Format probability range text like "34â€“46%" (bounded to 0..100)
f_prob_range_text(p, nBin) =>
    if nBin < calMinSamples or nBin <= 0
        "build n" + str.tostring(nBin)
    else
        band = f_unc_pp(p, nBin) / 100.0
        lo = math.max(0.0, p - band)
        hi = math.min(1.0, p + band)
        str.tostring(lo * 100.0, "#.0") + "â€“" + str.tostring(hi * 100.0, "#.0") + "%"

//====================
// Helpers â€” Evaluation (proper scoring + rolling stats)
//====================
f_epsClamp(p) =>
    eps = 1e-6
    math.max(eps, math.min(1.0 - eps, p))

f_brier(p, y) =>
    // y in {0.0, 1.0}
    d = p - y
    d * d

f_logloss(p, y) =>
    // y in {0.0, 1.0}
    pc = f_epsClamp(p)
    -(y * math.log(pc) + (1.0 - y) * math.log(1.0 - pc))

// @function Adds value to rolling buffer and maintains running sum
// @param buf Rolling buffer array
// @param sumArr Single-element array holding running sum
// @param v Value to add
// @param maxLen Maximum buffer length
// @note Periodic recalculation every ROLL_RECALC_INTERVAL bars prevents FP drift
f_roll_add(buf, sumArr, v, maxLen) =>
    array.push(buf, v)
    array.set(sumArr, 0, array.get(sumArr, 0) + v)
    if array.size(buf) > maxLen
        old = array.shift(buf)
        array.set(sumArr, 0, array.get(sumArr, 0) - old)
    // Periodic recalculation to prevent floating-point drift
    if bar_index % ROLL_RECALC_INTERVAL == 0 and array.size(buf) > 0
        array.set(sumArr, 0, array.sum(buf))

f_bucket(p, B) =>
    // p in [0,1], B buckets
    b = int(math.floor(p * B))
    b < 0 ? 0 : b > (B - 1) ? (B - 1) : b

f_cal_roll_update(calCnt, calSumP, calSumY, bBuf, pBuf, yBuf, p, y, maxLen) =>
    B = array.size(calCnt)
    bi = f_bucket(p, B)

    // push
    array.push(bBuf, bi)
    array.push(pBuf, p)
    array.push(yBuf, y)

    // increment bucket accumulators
    array.set(calCnt,  bi, array.get(calCnt,  bi) + 1)
    array.set(calSumP, bi, array.get(calSumP, bi) + p)
    array.set(calSumY, bi, array.get(calSumY, bi) + y)

    // enforce rolling length
    if array.size(bBuf) > maxLen
        bOld = array.shift(bBuf)
        pOld = array.shift(pBuf)
        yOld = array.shift(yBuf)

        array.set(calCnt,  bOld, math.max(0, array.get(calCnt,  bOld) - 1))
        array.set(calSumP, bOld, array.get(calSumP, bOld) - pOld)
        array.set(calSumY, bOld, array.get(calSumY, bOld) - yOld)

f_eval_stats_one(brierBuf, sumBrier, logBuf, sumLog, ySBuf, sumYS, yLBuf, sumYL, calCnt, calSumP, calSumY) =>
    nScore = array.size(brierBuf)
    brierAvg = nScore == 0 ? na : array.get(sumBrier, 0) / nScore
    logAvg   = nScore == 0 ? na : array.get(sumLog,   0) / nScore

    nS = array.size(ySBuf)
    nL = array.size(yLBuf)
    wS = nS == 0 ? na : array.get(sumYS, 0) / nS
    wL = nL == 0 ? na : array.get(sumYL, 0) / nL
    drift = (na(wS) or na(wL)) ? na : (wS - wL)

    // ECE from rolling buckets
    tot = 0
    for i = 0 to array.size(calCnt) - 1
        tot += array.get(calCnt, i)

    ece = float(na)
    maxErr = float(na)
    if tot > 0
        e = 0.0
        m = 0.0
        for i = 0 to array.size(calCnt) - 1
            c = array.get(calCnt, i)
            if c > 0
                ap = array.get(calSumP, i) / c
                ay = array.get(calSumY, i) / c
                err = math.abs(ap - ay)
                e += err * (c / tot)
                m := math.max(m, err)
        ece := e
        maxErr := m

    [brierAvg, logAvg, ece, maxErr, wS, wL, drift, nScore]

f_strengthLabel(n) =>
    n < 30 ? "weak" : n < 100 ? "ok" : "strong"

f_pp(x) =>
    // x in [0,1] -> "12.3%"
    str.tostring(x * 100.0, "#.0") + "%"

f_ppSigned(x) =>
    // x in [-1,1] -> "+4.0pp"
    pp = x * 100.0
    (pp >= 0 ? "+" : "") + str.tostring(pp, "#.0") + "pp"

f_colLowerBetter(x, good, ok) =>
    na(x) ? color.new(color.white, 60) : x <= good ? color.lime : x <= ok ? color.yellow : color.red

// --- â€œChanceâ€ cell text (arrow + percent), but human warmup/off states
f_chance_text(tf, pUp, nBin, total, canCal) =>
    if not canCal or total <= 0
        "â€”"
    else if nBin < calMinSamples
        f_target_label(tf) + " â€¦"
    else
        sym = pUp > predUpThr ? "â–²" : pUp < predDnThr ? "â–¼" : "âˆ’"
        sym + " " + f_target_label(tf) + " " + str.tostring(pUp * 100.0, "#.0") + "%"

// --- â€œDataâ€ cell text: bin/total + label + optional Â±CI
f_data_text(pUp, nBin, total, canCal) =>
    if not canCal
        "off"
    else if total <= 0
        "n0"
    else
        lbl = f_strength_label_fc(nBin)
        rng = f_prob_range_text(pUp, nBin)
        str.tostring(nBin) + "/" + str.tostring(total) + "\n" + lbl + " (" + rng + ")"

f_clamp01(x) =>
    math.max(0.0, math.min(1.0, x))

// @function Clamp value to arbitrary [lo, hi] range
// @param val Value to clamp
// @param lo Minimum bound
// @param hi Maximum bound
// @returns Clamped value
f_clamp(val, lo, hi) =>
    math.max(lo, math.min(hi, val))

f_pct_rank(x, len) =>
    lo = ta.lowest(x, len)
    hi = ta.highest(x, len)
    hi == lo ? 0.5 : (x - lo) / (hi - lo)

f_tfLabel(tf) =>
    tf == "1"   ? "1M"  : tf == "5"   ? "5M"  : tf == "15"  ? "15M" : tf == "30"  ? "30M" : tf == "60"  ? "1H"  : tf == "240" ? "4H"  : tf == "D"   ? "1D"  : tf

f_confColor(val) =>
    val > 0.70 ? color.lime : val <= 0.45 ? color.red : color.yellow

f_fmtVol(v) =>
    na(v) ? "â€”" : v >= 1000000000.0 ? (str.tostring(v / 1000000000.0, "#.###") + "B") : v >= 1000000.0    ? (str.tostring(v / 1000000.0, "#.###") + "M") : v >= 1000.0       ? (str.tostring(v / 1000.0, "#.###") + "K") : str.tostring(v, "#")

f_state_score(c, emaF_tf, emaS_tf, r_tf) =>
    trend = emaF_tf > emaS_tf ? 1.0 : emaF_tf < emaS_tf ? -1.0 : 0.0
    mom   = r_tf > 55 ? 1.0 : r_tf < 45 ? -1.0 : 0.0
    loc   = c > emaS_tf ? 0.5 : c < emaS_tf ? -0.5 : 0.0
    f_clamp01((trend + mom + loc + 2.0) / 4.0) * 2.0 - 1.0

f_state_tml(c, emaF_tf, emaS_tf, r_tf) =>
    t = emaF_tf > emaS_tf ? 1 : emaF_tf < emaS_tf ? -1 : 0
    m = r_tf > 55 ? 1 : r_tf < 45 ? -1 : 0
    l = c > emaS_tf ? 1 : c < emaS_tf ? -1 : 0
    [t, m, l]

// --- Phase 1 Helpers: Target Params ---
f_get_params(tf) =>
    sec = timeframe.in_seconds(tf)
    isFast = sec <= 300 // <= 5m
    isMid  = sec <= 3600 // <= 1h
    // Returns: [fcTarget, kBars, atrThr, pathH, tpATR, slATR]
    [isFast ? fcTargetF : isMid ? fcTargetM : fcTargetS, 
     isFast ? kBarsF    : isMid ? kBarsM    : kBarsS, 
     isFast ? atrThrF   : isMid ? atrThrM   : atrThrS, 
     isFast ? pathHF    : isMid ? pathHM    : pathHS, 
     isFast ? tpATRF    : isMid ? tpATRM    : tpATRS, 
     isFast ? slATRF    : isMid ? slATRM    : slATRS]

// --- Phase 4 Helpers: Platt Scaling ---
f_logit(p) =>
    pc = math.max(PROB_EPS, math.min(1.0 - PROB_EPS, p))
    math.log(pc / (1.0 - pc))

f_sigmoid(x) =>
    1.0 / (1.0 + math.exp(-x))

f_platt_prob(pRaw, a, b) =>
    usePlatt ? f_sigmoid(a * f_logit(pRaw) + b) : pRaw

// --- Phase 3 Helpers: Ensemble ---
f_pullback_score(c, ef, es, bias) =>
    // Bias 1 (Bull): shallow PB to EMAF is good (+1), deep to EMAS is neutral (0), below is bad (-1)
    // Simplified: Normalized distance
    float s = 0.0
    if bias == 1
        // If c > ef (start of pull), dist > 0. If c < ef, dist < 0.
        // We want: slightly negative is Good (pullback). Strongly negative is Bad (break).
        // Strongly positive is Extended (maybe pullback coming).
        // Let's us simple logic: 
        // Above EMA F: +0.5
        // Between F and S: +1.0 (Sweet spot)
        // Below S: -1.0
        if c > ef
            s := 0.5
        else if c > es
            s := 1.0
        else
            s := -1.0
    else if bias == -1
        if c < ef
            s := 0.5
        else if c < es
            s := 1.0
        else
            s := -1.0
    s

f_ensemble(sA, sB, sC, wA, wB, wC) =>
    num = wA * sA + wB * sB + wC * sC
    den = wA + wB + wC
    val = den == 0 ? 0.0 : num / den
    math.max(-1.0, math.min(1.0, val))

f_tf_pack(tf) =>
    request.security(
        syminfo.tickerid,
        tf,
        [time, close, high, low,
         ta.ema(close, emaFastLen),
         ta.ema(close, emaSlowLen),
         ta.rsi(close, rsiStateLen),
         ta.atr(atrTargetLen),
         f_pct_rank(ta.atr(atrLen)/close, volRankLen)], // Added Phase 2 Vol Rank
        barmerge.gaps_off,
        barmerge.lookahead_off
    )

f_score_tf(tf) =>
    [c, ef, es, r] = request.security(
            syminfo.tickerid,
            tf,
            [close,
             ta.ema(close, emaFastLen),
             ta.ema(close, emaSlowLen),
             ta.rsi(close, rsiStateLen)],
            barmerge.gaps_off,
            barmerge.lookahead_off
        )
    f_state_score(c, ef, es, r)

// Forecast binning / calibration
f_bin(score, bins) =>
    u = (score + 1.0) * 0.5
    b = int(math.floor(u * bins))
    b < 0 ? 0 : b > (bins - 1) ? (bins - 1) : b

// Phase 2: 2D Binning (State + Vol)
// @function Computes 2D bin index from score and volatility rank
// @param score Ensemble score in [-1, 1]
// @param volRank Volatility percentile rank in [0, 1]
// @param binsA Number of bins for score dimension
// @param binsB Number of bins for volatility dimension (typically 3)
// @returns Flattened bin index
f_bin2D(score, volRank, binsA, binsB) =>
    // Bin A (Score) - map [-1,1] to [0,1] then to bin index
    u = (score + 1.0) * 0.5
    bA = int(math.floor(u * binsA))
    bA := math.max(0, math.min(binsA - 1, bA))
    
    // Bin B (Vol Rank 0..1)
    // 3 bins: 0-LOW (Low), LOW-HIGH (Med), HIGH-1.0 (High)
    bB = 0
    if volRank >= VOL_THRESH_HIGH
        bB := 2
    else if volRank >= VOL_THRESH_LOW
        bB := 1
    
    // Flattened index
    int(bA * binsB + bB)

// @function Computes Bayesian probability with Platt scaling
// @param up Number of positive outcomes
// @param n Total number of samples
// @param alpha Laplace smoothing parameter
// @param aPlatt Platt scaling slope
// @param bPlatt Platt scaling intercept
// @returns Calibrated probability after Platt transformation
f_prob_platt(up, n, alpha, aPlatt, bPlatt) =>
    denom = n + 2.0 * alpha
    pRaw = denom == 0.0 ? 0.5 : (up + alpha) / denom
    f_platt_prob(pRaw, aPlatt, bPlatt)

// @function Computes Laplace-smoothed probability with division safety
// @param up Number of positive outcomes
// @param n Total number of samples
// @param alpha Laplace smoothing parameter (default typically 1.0)
// @returns Probability in (0, 1), defaults to 0.5 if denominator is zero
f_prob(up, n, alpha) =>
    denom = n + 2.0 * alpha
    denom == 0.0 ? 0.5 : (up + alpha) / denom

f_cal_update(cntArr, upArr, bin, isUp) =>
    n0 = array.get(cntArr, bin)
    u0 = array.get(upArr,  bin)
    array.set(cntArr, bin, n0 + 1)
    array.set(upArr,  bin, u0 + (isUp ? 1 : 0))

f_cal_cur(cntArr, upArr, bin, alpha, shrinkK) =>
    // Bin raw
    n = array.get(cntArr, bin)
    u = array.get(upArr,  bin)
    pBin = n == 0 ? 0.5 : f_prob(u, n, alpha)

    // Base rate (pooling)
    nBase = array.sum(cntArr)
    uBase = array.sum(upArr)
    pBase = nBase == 0 ? 0.5 : f_prob(uBase, nBase, alpha)

    // Shrinkage
    w = (shrinkK <= 0) ? 1.0 : (n / (n + shrinkK + 0.0))
    pFinal = w * pBin + (1.0 - w) * pBase
    [pFinal, n]

f_predSymbolP(pUp, n, canCal) =>
    not canCal ? "â€”" : n < calMinSamples ? "â€¦" : pUp > predUpThr ? "â–²" : pUp < predDnThr ? "â–¼" : "âˆ’"

f_predColorP(pUp, n, canCal, neutralCol) =>
    not canCal ? color.new(color.white, 70) : n < calMinSamples ? color.new(color.white, 60) : pUp > predUpThr ? color.lime : pUp < predDnThr ? color.red : neutralCol

f_pupText(pUp, n, canCal) =>
    if not canCal
        "OFF"
    else if n == 0
        "â€”"
    else if n < calMinSamples
        "Warm " + str.tostring(n) + "/" + str.tostring(calMinSamples)
    else
        if fcDisplay == "Edge pp (N)"
            edge = (pUp - 0.5) * 100.0
            sign = edge > 0 ? "+" : ""
            // example: +2.3pp (203)
            sign + str.tostring(edge, "#.0") + "pp (" + str.tostring(n) + ")"
        else
            // example: Up 49.8% (203)
            "Up " + str.tostring(pUp * 100.0, "#.0") + "% (" + str.tostring(n) + ")"

f_eval_update_one(p, y,
    brierBuf, sumBrier,
    logBuf,   sumLog,
    ySBuf,    sumYS,
    yLBuf,    sumYL,
    calCnt, calSumP, calSumY,
    calBBuf, calPBuf, calYBuf) =>

    // optional live-only gate
    canEval = (evalMode == "History+Live") or barstate.isrealtime
    if canEval
        pc = f_epsClamp(p)

        // rolling scores
        f_roll_add(brierBuf, sumBrier, f_brier(pc, y), evalRollScore)
        f_roll_add(logBuf,   sumLog,   f_logloss(pc, y), evalRollScore)

        // rolling win rates
        f_roll_add(ySBuf, sumYS, y, evalRollShort)
        f_roll_add(yLBuf, sumYL, y, evalRollLong)

        // rolling calibration buckets (ECE)
        f_cal_roll_update(calCnt, calSumP, calSumY, calBBuf, calPBuf, calYBuf, pc, y, evalRollScore)

f_eval_on_resolve(TfState st, pN, p1, isUpBool) =>
    y = isUpBool ? 1.0 : 0.0

    f_eval_update_one(pN, y, st.evBrierN, st.evSumBrierN, st.evLogN, st.evSumLogN, st.evYS_N, st.evSumYS_N, st.evYL_N, st.evSumYL_N, st.evCalCntN, st.evCalSumPN, st.evCalSumYN, st.evCalBBufN, st.evCalPBufN, st.evCalYBufN)
    f_eval_update_one(p1, y, st.evBrier1, st.evSumBrier1, st.evLog1, st.evSumLog1, st.evYS_1, st.evSumYS_1, st.evYL_1, st.evSumYL_1, st.evCalCnt1, st.evCalSumP1, st.evCalSumY1, st.evCalBBuf1, st.evCalPBuf1, st.evCalYBuf1)

f_reset_tf(TfState st) =>
    array.fill(st.cntN, 0), array.fill(st.upN, 0)
    array.fill(st.cnt1, 0), array.fill(st.up1, 0)

    array.clear(st.qBinN)
    array.clear(st.qBin1)
    array.clear(st.qEntry)
    array.clear(st.qAtr)
    array.clear(st.qMaxH)
    array.clear(st.qMinL)
    array.clear(st.qAge)
    
    // Brier tracking clear
    array.clear(st.qProbN)
    array.clear(st.qProb1)
    array.clear(st.qLogitN)
    array.clear(st.qLogit1)
    array.clear(st.qPredN)
    array.clear(st.qPred1)
    
    // Stats clear
    array.set(st.brierStatsN, 0, 0.0)
    array.set(st.brierStatsN, 1, 0.0)
    array.set(st.brierStats1, 0, 0.0)
    array.set(st.brierStats1, 1, 0.0)
    array.set(st.llStatsN, 0, 0.0)
    array.set(st.llStatsN, 1, 0.0)
    array.set(st.llStats1, 0, 0.0)
    array.set(st.llStats1, 1, 0.0)
    // Platt Reset (Identity)
    array.set(st.plattN, 0, 1.0)
    array.set(st.plattN, 1, 0.0)
    array.set(st.platt1, 0, 1.0)
    array.set(st.platt1, 1, 0.0)

f_reset_one_state_eval(TfState st) =>
    array.clear(st.evBrierN), array.clear(st.evSumBrierN), array.clear(st.evLogN), array.clear(st.evSumLogN), array.clear(st.evYS_N), array.clear(st.evSumYS_N), array.clear(st.evYL_N), array.clear(st.evSumYL_N)
    array.fill(st.evCalCntN, 0), array.fill(st.evCalSumPN, 0.0), array.fill(st.evCalSumYN, 0.0)
    array.clear(st.evCalBBufN), array.clear(st.evCalPBufN), array.clear(st.evCalYBufN)

    array.clear(st.evBrier1), array.clear(st.evSumBrier1), array.clear(st.evLog1), array.clear(st.evSumLog1), array.clear(st.evYS_1), array.clear(st.evSumYS_1), array.clear(st.evYL_1), array.clear(st.evSumYL_1)
    array.fill(st.evCalCnt1, 0), array.fill(st.evCalSumP1, 0.0), array.fill(st.evCalSumY1, 0.0)
    array.clear(st.evCalBBuf1), array.clear(st.evCalPBuf1), array.clear(st.evCalYBuf1)

f_reset_eval_all() =>
    f_reset_one_state_eval(tf1State)
    f_reset_one_state_eval(tf2State)
    f_reset_one_state_eval(tf3State)
    f_reset_one_state_eval(tf4State)
    f_reset_one_state_eval(tf5State)
    f_reset_one_state_eval(tf6State)
    f_reset_one_state_eval(tf7State)

// Process one TF calibration step (updates on new TF bar)
// @param _hid Horizon ID (1-7) - reserved for debugging/logging
// @param newTfBar True when a new timeframe bar starts
// @param sA Algorithm score for ensemble calculation
// @param cNow Current close price
// @param hNow Current high price
// @param lNow Current low price
// @param atrNow Current ATR value
// @param volRankNow Current volatility rank [0,1]
// @param emaFNow Fast EMA value
// @param emaSNow Slow EMA value
// @param st TfState UDT containing all state arrays
// @param fcTgt Forecast target type
// @param kB K-bar horizon
// @param aThr ATR threshold
// @param pH Path horizon
// @param tpA Take-profit ATR multiplier
// @param slA Stop-loss ATR multiplier
// @param alphaNVal Alpha for N-bin smoothing
// @param alpha1Val Alpha for 1-bin smoothing
// @param shrinkKVal Shrinkage factor
// @param wAVal Weight for trend score
// @param wBVal Weight for pullback score
// @param wCVal Weight for volatility bias
f_process_tf(_hid, newTfBar, sA, 
             cNow, hNow, lNow, atrNow, volRankNow, emaFNow, emaSNow,
             TfState st,
             fcTgt, kB, aThr, pH, tpA, slA,
             alphaNVal, alpha1Val, shrinkKVal, wAVal, wBVal, wCVal) =>

    if newTfBar
        // 1) Age/extremes update for pending items
        sz = array.size(st.qAge)
        if sz > 0
            for i = 0 to sz - 1
                age = array.get(st.qAge, i) + 1
                array.set(st.qAge, i, age)
                mh = math.max(array.get(st.qMaxH, i), hNow)
                ml = math.min(array.get(st.qMinL, i), lNow)
                array.set(st.qMaxH, i, mh)
                array.set(st.qMinL, i, ml)

        // 2) Resolve items (descending while loop => safe with removals)
        i = array.size(st.qAge) - 1
        while i >= 0
            age_i   = array.get(st.qAge,   i)
            entry_i = array.get(st.qEntry, i)
            atr_i   = array.get(st.qAtr,   i)
            mh_i    = array.get(st.qMaxH,  i)
            ml_i    = array.get(st.qMinL,  i)
            bN_i    = array.get(st.qBinN,  i)
            b1_i    = array.get(st.qBin1,  i)

            // Stored at entry
            probN_i = array.get(st.qProbN,  i)
            prob1_i = array.get(st.qProb1,  i)
            lgtN_i  = array.get(st.qLogitN, i)
            lgt1_i  = array.get(st.qLogit1, i)

            // the probabilities predicted at entry time
            pPredN_i = array.get(st.qPredN, i)
            pPred1_i = array.get(st.qPred1, i)

            resolved = false
            doUpdate = false
            isUp     = false

            // --- Phase 1: Local Target Logic ---
            if fcTgt == "NextBar"
                if age_i >= 1
                    resolved := true
                    doUpdate := true
                    isUp := cNow > entry_i

            else if fcTgt == "KBarReturn"
                if age_i >= kB
                    resolved := true
                    doUpdate := true
                    isUp := cNow > entry_i

            else if fcTgt == "KBarATR"
                if age_i >= kB
                    resolved := true
                    // Skip calibration update if ATR is invalid (prevents misleading ratios)
                    if na(atr_i) or atr_i == 0.0
                        doUpdate := false
                    else
                        doUpdate := true
                        retATR = (cNow - entry_i) / atr_i
                        isUp := retATR >= aThr

            else // PathTPvsSL
                tpPx = entry_i + tpA * atr_i
                slPx = entry_i - slA * atr_i
                winHit  = mh_i >= tpPx
                lossHit = ml_i <= slPx

                if winHit or lossHit
                    resolved := true
                    doUpdate := true
                    if winHit and lossHit
                        if pathTiePolicy == "Win"
                            isUp := true
                        else if pathTiePolicy == "Neutral"
                            doUpdate := false
                        else
                            isUp := false
                    else
                        isUp := winHit and not lossHit

                else if age_i >= pH
                    resolved := true
                    if noHitPolicy == "Loss"
                        doUpdate := true
                        isUp := false
                    else
                        doUpdate := false

            if resolved
                if doUpdate
                    f_cal_update(st.cntN, st.upN, bN_i, isUp)
                    f_cal_update(st.cnt1, st.up1, b1_i, isUp)
                    
                    outcomeVal = isUp ? 1.0 : 0.0

                    // evaluation scoring (NEW)
                    f_eval_on_resolve(st, pPredN_i, pPred1_i, isUp)

                    // --- Phase 4: SGD Update & LogLoss (N) ---
                    // N (Gated Logic)
                    nBinN_cur = array.get(st.cntN, bN_i)
                    if nBinN_cur >= calMinSamples
                        // Brier on raw prob
                        sqErrN = math.pow(outcomeVal - probN_i, 2)
                        curSumN = array.get(st.brierStatsN, 0)
                        curCntN = array.get(st.brierStatsN, 1)
                        array.set(st.brierStatsN, 0, curSumN + sqErrN)
                        array.set(st.brierStatsN, 1, curCntN + 1.0)
                        
                        // Platt SGD
                        if usePlatt
                            aN = array.get(st.plattN, 0)
                            bN = array.get(st.plattN, 1)
                            pAdj = f_sigmoid(aN * lgtN_i + bN)
                            err = pAdj - outcomeVal
                            da = err * lgtN_i
                            db = err
                            // Update
                            aN := math.max(0.1, math.min(5.0, aN - lrPlatt * da)) 
                            bN := math.max(-3.0, math.min(3.0, bN - lrPlatt * db))
                            array.set(st.plattN, 0, aN)
                            array.set(st.plattN, 1, bN)
                            
                            // LogLoss
                            pLL = math.max(PROB_EPS, math.min(1.0 - PROB_EPS, pAdj))
                            ll = -(outcomeVal * math.log(pLL) + (1.0 - outcomeVal) * math.log(1.0 - pLL))
                            curSumLL = array.get(st.llStatsN, 0)
                            curCntLL = array.get(st.llStatsN, 1)
                            array.set(st.llStatsN, 0, curSumLL + ll)
                            array.set(st.llStatsN, 1, curCntLL + 1.0)
                    
                    // --- Phase 4: SGD Update & LogLoss (1) ---
                    sqErr1 = math.pow(outcomeVal - prob1_i, 2)
                    curSum1 = array.get(st.brierStats1, 0)
                    curCnt1 = array.get(st.brierStats1, 1)
                    array.set(st.brierStats1, 0, curSum1 + sqErr1)
                    array.set(st.brierStats1, 1, curCnt1 + 1.0)

                    if usePlatt
                        a1 = array.get(st.platt1, 0)
                        b1 = array.get(st.platt1, 1)
                        pAdj1 = f_sigmoid(a1 * lgt1_i + b1)
                        err1 = pAdj1 - outcomeVal
                        da1 = err1 * lgt1_i
                        db1 = err1
                        a1 := math.max(0.1, math.min(5.0, a1 - lrPlatt * da1)) 
                        b1 := math.max(-3.0, math.min(3.0, b1 - lrPlatt * db1))
                        array.set(st.platt1, 0, a1)
                        array.set(st.platt1, 1, b1)
                        
                        pLL1 = math.max(PROB_EPS, math.min(1.0 - PROB_EPS, pAdj1))
                        ll1 = -(outcomeVal * math.log(pLL1) + (1.0 - outcomeVal) * math.log(1.0 - pLL1))
                        curSumLL1 = array.get(st.llStats1, 0)
                        curCntLL1 = array.get(st.llStats1, 1)
                        array.set(st.llStats1, 0, curSumLL1 + ll1)
                        array.set(st.llStats1, 1, curCntLL1 + 1.0)

                array.remove(st.qAge,   i)
                array.remove(st.qMaxH,  i)
                array.remove(st.qMinL,  i)
                array.remove(st.qAtr,   i)
                array.remove(st.qEntry, i)
                array.remove(st.qBinN,  i)
                array.remove(st.qBin1,  i)
                array.remove(st.qProbN, i)
                array.remove(st.qProb1, i)
                array.remove(st.qLogitN, i)
                array.remove(st.qLogit1, i)
                array.remove(st.qPredN, i)
                array.remove(st.qPred1, i)

            i -= 1

        // 3) Push new pending item
        // --- Phase 3: Ensemble Score ---
        bias = emaFNow > emaSNow ? 1 : -1
        sB = f_pullback_score(cNow, emaFNow, emaSNow, bias)
        sC = volRankNow >= VOL_THRESH_HIGH ? -1.0 : (volRankNow <= VOL_THRESH_LOW ? 1.0 : 0.0)
        sEns = f_ensemble(sA, sB, sC, wAVal, wBVal, wCVal)
        
        // --- Phase 2: 2D Binning ---
        bN = f_bin2D(sEns, volRankNow, predBinsN, dim2Bins)
        b1 = f_bin2D(sEns, volRankNow, predBins1, dim2Bins)

        // Capture current probabilities
        [pNowN, _nN] = f_cal_cur(st.cntN, st.upN, bN, alphaNVal, shrinkKVal)
        [pNow1, _n1] = f_cal_cur(st.cnt1, st.up1, b1, alpha1Val, shrinkKVal)
        
        // Logits (Phase 4)
        lgtN = f_logit(pNowN)
        lgt1 = f_logit(pNow1)

        array.push(st.qBinN,  bN)
        array.push(st.qBin1,  b1)
        array.push(st.qEntry, cNow)
        array.push(st.qAtr,   atrNow)

        array.push(st.qMaxH,  cNow)
        array.push(st.qMinL,  cNow)

        array.push(st.qAge,   0)
        
        array.push(st.qProbN, pNowN)
        array.push(st.qProb1, pNow1)
        array.push(st.qLogitN, lgtN)
        array.push(st.qLogit1, lgt1)
        
        array.push(st.qPredN, pNowN)
        array.push(st.qPred1, pNow1)
// Core indicators
//====================
emaF = ta.ema(close, emaFastLen)
emaS = ta.ema(close, emaSlowLen)
atr  = ta.atr(atrLen)

// Adaptive RSI length (for confidence momentum only)
baseSecs = timeframe.in_seconds(timeframe.period)
rsiLenUse = useAdaptiveRsi ?
     ((not na(baseSecs) and baseSecs <= timeframe.in_seconds("300"))  ? rsiLenFastTF :
      (not na(baseSecs) and baseSecs <= timeframe.in_seconds("3600")) ? rsiLenMidTF  :
                                                                        rsiLenSlowTF) :
     rsiLenSlowTF
rsiConf = ta.rsi(close, rsiLenUse)

// Crosses (computed every bar)
crossEmaF_EmaS_up   = ta.crossover(emaF, emaS)
crossEmaF_EmaS_down = ta.crossunder(emaF, emaS)

crossClose_EmaF_up   = ta.crossover(close, emaF)
crossClose_EmaF_down = ta.crossunder(close, emaF)

crossClose_EmaS_up   = ta.crossover(close, emaS)
crossClose_EmaS_down = ta.crossunder(close, emaS)

// Vol regime
atrRank = f_pct_rank(atr / close, volRankLen)

// Guardrails
prevClose = close[1]
gapPct    = (na(prevClose) or prevClose == 0.0) ? 0.0 : math.abs(open - prevClose) / prevClose
rangePct  = close == 0.0 ? 0.0 : (high - low) / close
volShock  = atrRank >= volRankHigh
gapShock  = gapPct >= gapShockPct
rangeShock= rangePct >= rangeShockPct
guardrailCount = (volShock ? 1 : 0) + (gapShock ? 1 : 0) + (rangeShock ? 1 : 0)

// Data quality proxy
volAvail = not na(volume)
volRankRaw = f_pct_rank(volume, volRankLen)
dataQualityScore = volAvail ? volRankRaw : 0.5

// Macro
macroLen = timeframe.isintraday ? math.min(macroPctLen, macroPctLenIntraday) : macroPctLen
macroPct = f_pct_rank(close, macroLen)
macroScoreRaw = f_clamp01(1.0 - macroPct)
macroScore = macroGateMode == "Off" ? 0.5 : macroScoreRaw
macroGateLong  = macroGateMode == "Hard Gate" ? (not na(macroPct) and macroPct < macroLongPctThreshold)  : true
macroGateShort = macroGateMode == "Hard Gate" ? (not na(macroPct) and macroPct > macroShortPctThreshold) : true

// Drawdown
ddPeak = ta.highest(close, ddLookback)
dd     = ddPeak == 0.0 ? 0.0 : (close - ddPeak) / ddPeak
ddAbs  = math.max(0.0, -dd)
ddSeverity = f_clamp01((ddAbs - ddMild) / math.max(ddSevere - ddMild, 0.0001))
ddPenalty  = ddTrustPenalty * ddSeverity
ddHardGateHit = ddHardGate > 0.0 and ddAbs >= ddHardGate

// Direction bias + confidence
bullBias = emaF > emaS
bearBias = emaF < emaS
baseDir  = bullBias ? 1 : bearBias ? -1 : 0
trustDir = baseDir == 0 ? 1 : baseDir

// Momentum hysteresis state
var bool momLongOnState  = false
var bool momShortOnState = false
var bool momStateInit    = false

if not na(rsiConf)
    if not momStateInit
        momLongOnState  := rsiConf > 50.0
        momShortOnState := rsiConf < 50.0
        momStateInit    := true
    else
        if (not momLongOnState) and (rsiConf > rsiLongOn)
            momLongOnState := true
        else if momLongOnState and (rsiConf < rsiLongOff)
            momLongOnState := false

        if (not momShortOnState) and (rsiConf < rsiShortOn)
            momShortOnState := true
        else if momShortOnState and (rsiConf > rsiShortOff)
            momShortOnState := false

// Connors RSI
var float streak = 0.0
if na(close[1])
    streak := 0.0
else
    if close > close[1]
        streak := streak >= 0 ? streak + 1 : 1
    else if close < close[1]
        streak := streak <= 0 ? streak - 1 : -1
    else
        streak := 0.0

chgClose = ta.change(close)  // global per-bar
crsiRsiPart    = ta.rsi(close,  crsiRsiLen)
crsiStreakPart = ta.rsi(streak, crsiStreakRsiLen)
crsiRankPart   = f_pct_rank(chgClose, crsiRankLen) * 100.0
crsi           = (crsiRsiPart + crsiStreakPart + crsiRankPart) / 3.0

longFactor = crsi < crsiLongPanic ? crsiLongPanicMult : crsi > crsiLongOver  ? crsiLongOverMult  : (crsi >= crsiLongGoodLo and crsi <= crsiLongGoodHi) ? crsiLongGoodMult : 1.0

shortFactor = crsi < crsiShortExhaust ? crsiShortExhaustMult : crsi > crsiShortOver    ? crsiShortOverMult    : (crsi >= crsiShortGoodLo and crsi <= crsiShortGoodHi) ? crsiShortGoodMult : 1.0

crsiFactor = (not useCrsiFactor) ? 1.0 : (bullBias ? longFactor : bearBias ? shortFactor : 1.0)

// Strength calc
rsi7 = ta.rsi(close, 7)

// Trust score
f_trust_score(dir, guardrailCount_, volRank_, dataQualityScore_, macroScore_, momOkLong_, momOkShort_) =>
    emaF_ = ta.ema(close, emaFastLen)
    emaS_ = ta.ema(close, emaSlowLen)

    trendOk = dir == 1 ? (emaF_ > emaS_ and close > emaS_) : (emaF_ < emaS_ and close < emaS_)
    momOk   = dir == 1 ? momOkLong_ : momOkShort_

    accuracyScore = (trendOk ? 0.6 : 0.0) + (momOk ? 0.4 : 0.0)

    regimeScore     = volRank_ >= volRankHigh ? 0.4 : volRank_ >= volRankMed ? 0.7 : 1.0
    guardrailScore  = f_clamp01(1.0 - (guardrailCount_ * penaltyGuardrail))

    wSum = trustWAccuracy + trustWRegime + trustWGuardrail + trustWData + trustWMacro
    wSum := wSum == 0.0 ? 1.0 : wSum

    base = (
        trustWAccuracy  * accuracyScore +
        trustWRegime    * regimeScore +
        trustWGuardrail * guardrailScore +
        trustWData      * dataQualityScore_ +
        trustWMacro     * macroScore_
    ) / wSum

    extraPenalty = volRank_ >= volRankHigh ? penaltyRegimeHigh : volRank_ >= volRankMed ? penaltyRegimeMed : 0.0
    f_clamp01(base - extraPenalty)

confMultiplier =
     config == "Standard"      ? 1.00 :
     config == "Pro"           ? 1.05 :
     config == "V2 Essential"  ? 0.95 :
     config == "V2 Proficient" ? 1.00 : 1.10

trustRaw   = f_trust_score(trustDir, guardrailCount, atrRank, dataQualityScore, macroScore, momLongOnState, momShortOnState)
confidence = f_clamp01(trustRaw * confMultiplier)
confidence := f_clamp01(confidence * (1.0 - ddPenalty))
confidence := f_clamp01(confidence * crsiFactor)

//====================
// MTF confirmation
//====================
mtfBaseSecs = timeframe.in_seconds(timeframe.period)
autoSet  = (not na(mtfBaseSecs) and mtfBaseSecs <= timeframe.in_seconds("30"))  ? "Short" :
           (not na(mtfBaseSecs) and mtfBaseSecs <= timeframe.in_seconds("240")) ? "Medium" : "Long"
setUse   = mtfSet == "Auto" ? autoSet : mtfSet

f_is_tf_higher_or_equal(tf) =>
    base  = timeframe.in_seconds(timeframe.period)
    other = timeframe.in_seconds(tf)
    not na(base) and not na(other) and other >= base

getVoteScore() =>
    float sum = 0.0
    float cnt = 0.0

    tf1 = setUse == "Short" ? tfShort1 : setUse == "Medium" ? tfMedium1 : tfLong1
    tf2 = setUse == "Short" ? tfShort2 : setUse == "Medium" ? tfMedium2 : tfLong2
    tf3 = setUse == "Short" ? tfShort3 : setUse == "Medium" ? tfMedium3 : tfLong3

    if f_is_tf_higher_or_equal(tf1)
        sum += f_score_tf(tf1)
        cnt += 1
    if f_is_tf_higher_or_equal(tf2)
        sum += f_score_tf(tf2)
        cnt += 1
    if f_is_tf_higher_or_equal(tf3)
        sum += f_score_tf(tf3)
        cnt += 1

    cnt == 0 ? 0.0 : sum / cnt

mtfScore   = useMtfConfirm ? getVoteScore() : 0.0
mtfOkLong  = (not useMtfConfirm) or (mtfScore > 0.05)
mtfOkShort = (not useMtfConfirm) or (mtfScore < -0.05)

// Gate requires: Confidence Logic + MTF Vote + Macro + Drawdown
gateLongNow  = (confidence >= minTrust) and mtfOkLong  and macroGateLong  and not ddHardGateHit
gateShortNow = (confidence >= minTrust) and mtfOkShort and macroGateShort and not ddHardGateHit

//====================
// Close filter (avoid entries right before RTH close)
//====================
sessClose      = timestamp(syminfo.timezone, year, month, dayofmonth, rthCloseHour, rthCloseMinute)
minsToClose    = (sessClose - time) / 60000.0
blockNearClose = useRthCloseFilter and timeframe.isintraday and (minsToClose >= 0) and (minsToClose <= avoidCloseMins)

//====================
// Zones (anchored)
//====================
var float entryPrice = na
vwapVal   = ta.vwap(hlc3)
sma200Val = ta.sma(close, 200)

zoneAnchorPrice =
     zoneAnchor == "Entry"    and not na(entryPrice) ? entryPrice :
     zoneAnchor == "VWAP"     ? vwapVal :
     zoneAnchor == "MA200"    ? sma200Val :
     zoneAnchor == "EMA Fast" ? emaF : emaS

neutralUpper = zoneAnchorPrice + zoneNeutralMult * atr
neutralLower = zoneAnchorPrice - zoneNeutralMult * atr

aggrUpper = zoneMode == "Symmetric" ? (zoneAnchorPrice + zoneAggressiveMult1 * atr) : (zoneAnchorPrice - zoneAggressiveMult1 * atr)
aggrLower = zoneMode == "Symmetric" ? (zoneAnchorPrice - zoneAggressiveMult2 * atr) : (zoneAnchorPrice - zoneAggressiveMult2 * atr)

//====================
// SET marker (Trend Continuation Setup)
//====================
setLong   = bullBias and (crsi < crsiLongGoodHi)
setShort  = bearBias and (crsi > crsiShortGoodLo)
setPulse  = barstate.isconfirmed and (setLong or setShort)

//====================
// Signal engine (exits not blocked by cooldown)
//====================
trendFlipUp   = ta.crossover(emaF, emaS)
trendFlipDown = ta.crossunder(emaF, emaS)
reclaimUp     = bullBias and crossClose_EmaF_up
reclaimDown   = bearBias and crossClose_EmaF_down

breakLong  = crossClose_EmaS_down or trendFlipDown
breakShort = crossClose_EmaS_up   or trendFlipUp

var int pos = 0
var int lastSignalBar = na
var string lastSig = "â€”"

cooldownOk   = na(lastSignalBar) ? true : (bar_index - lastSignalBar > cooldownBars)

f_getBrier(tfSel, modSel) =>
    float score = 0.5 // default safe
    
    // Select array pair stats
    float[] stats = na
    if tfSel == "F1"
        stats := (modSel == "N") ? tf1State.brierStatsN : tf1State.brierStats1
    else if tfSel == "F2"
        stats := (modSel == "N") ? tf2State.brierStatsN : tf2State.brierStats1
    else if tfSel == "F3"
        stats := (modSel == "N") ? tf3State.brierStatsN : tf3State.brierStats1
    else if tfSel == "F4"
        stats := (modSel == "N") ? tf4State.brierStatsN : tf4State.brierStats1
    else if tfSel == "F5"
        stats := (modSel == "N") ? tf5State.brierStatsN : tf5State.brierStats1
    else if tfSel == "F6"
        stats := (modSel == "N") ? tf6State.brierStatsN : tf6State.brierStats1
    else if tfSel == "F7"
        stats := (modSel == "N") ? tf7State.brierStatsN : tf7State.brierStats1
    
    if not na(stats)
        s = array.get(stats, 0)
        c = array.get(stats, 1)
        if c > 0
            score := s / c
    score

curBrier = f_getBrier(relFilterTF, relFilterModel)
reliabilityOk = (not useRelFilter) or (curBrier <= maxBrier)

allowEntry   = barstate.isconfirmed and cooldownOk and not blockNearClose and reliabilityOk
allowExit    = barstate.isconfirmed

buySignal   = false
exitSignal  = false
shortSignal = false
coverSignal = false

if engine == "Trend+Pullback"
    if pos == 0 and allowEntry
        buySignal   := gateLongNow and (trendFlipUp or reclaimUp)
        shortSignal := enableShorts and gateShortNow and (trendFlipDown or reclaimDown)
        if buySignal and shortSignal
            buySignal := false
            shortSignal := false
    if pos == 1 and allowExit
        exitSignal := breakLong and bearBias
    if pos == -1 and allowExit
        coverSignal := breakShort and bullBias

else if engine == "Loose"
    if pos == 0 and allowEntry
        buySignal   := gateLongNow and crossClose_EmaF_up
        shortSignal := enableShorts and gateShortNow and crossClose_EmaF_down
        if buySignal and shortSignal
            buySignal := false
            shortSignal := false
    if pos == 1 and allowExit
        exitSignal := breakLong and bearBias
    if pos == -1 and allowExit
        coverSignal := breakShort and bullBias

if barstate.isconfirmed
    if exitSignal and pos == 1
        pos := 0
        entryPrice := na
        lastSignalBar := bar_index
        lastSig := "EXIT"
    else if coverSignal and pos == -1
        pos := 0
        entryPrice := na
        lastSignalBar := bar_index
        lastSig := "COVER"
    else if buySignal and pos == 0
        pos := 1
        entryPrice := close
        lastSignalBar := bar_index
        lastSig := "BUY"
    else if shortSignal and pos == 0
        pos := -1
        entryPrice := close
        lastSignalBar := bar_index
        lastSig := "SHORT"

//====================
// Visuals
//====================
plotshape(showSetMarkers and setPulse, title="SET", style=shape.circle, location=location.belowbar, size=size.tiny, text="SET", textcolor=color.white, color=color.new(color.blue, 0))

if showEntryLabels and buySignal
    label.new(bar_index, low, "BUY\nConf " + str.tostring(confidence, format.mintick), style=label.style_label_up, textcolor=color.white, color=color.new(color.green, 0))
if showEntryLabels and shortSignal
    label.new(bar_index, high, "SHORT\nConf " + str.tostring(confidence, format.mintick), style=label.style_label_down, textcolor=color.white, color=color.new(color.red, 0))
if showEntryLabels and exitSignal
    label.new(bar_index, high, "EXIT\nConf " + str.tostring(confidence, format.mintick), style=label.style_label_down, textcolor=color.white, color=color.new(color.red, 0))
if showEntryLabels and coverSignal
    label.new(bar_index, low, "COVER\nConf " + str.tostring(confidence, format.mintick), style=label.style_label_up, textcolor=color.white, color=color.new(color.green, 0))

pNeutralUpper = plot(showZones ? neutralUpper : na, title="Neutral zone upper", linewidth=1, color=color.new(color.blue, 25))
pNeutralLower = plot(showZones ? neutralLower : na, title="Neutral zone lower", linewidth=1, color=color.new(color.blue, 25))
fill(pNeutralUpper, pNeutralLower, color=color.new(color.blue, 90))

pAggUpper = plot(showZones ? aggrUpper : na, title="Aggressive zone upper", linewidth=1, color=color.new(color.orange, 25))
pAggLower = plot(showZones ? aggrLower : na, title="Aggressive zone lower", linewidth=1, color=color.new(color.orange, 25))
fill(pAggUpper, pAggLower, color=color.new(color.orange, 88))

//====================
// Outlook/Forecast packs (one security call per horizon TF)
//====================
[t1, c1, h1, l1, ef1, es1, r1, a1, vR1] = f_tf_pack(tfF1)
[t2, c2, h2, l2, ef2, es2, r2, a2, vR2] = f_tf_pack(tfF2)
[t3, c3, h3, l3, ef3, es3, r3, a3, vR3] = f_tf_pack(tfF3)
[t4, c4, h4, l4, ef4, es4, r4, a4, vR4] = f_tf_pack(tfF4)
[t5, c5, h5, l5, ef5, es5, r5, a5, vR5] = f_tf_pack(tfF5)
[t6, c6, h6, l6, ef6, es6, r6, a6, vR6] = f_tf_pack(tfF6)
[t7, c7, h7, l7, ef7, es7, r7, a7, vR7] = f_tf_pack(tfF7)

chgT1 = ta.change(t1)
chgT2 = ta.change(t2)
chgT3 = ta.change(t3)
chgT4 = ta.change(t4)
chgT5 = ta.change(t5)
chgT6 = ta.change(t6)
chgT7 = ta.change(t7)

newF1 = not na(t1) and (chgT1 != 0)
newF2 = not na(t2) and (chgT2 != 0)
newF3 = not na(t3) and (chgT3 != 0)
newF4 = not na(t4) and (chgT4 != 0)
newF5 = not na(t5) and (chgT5 != 0)
newF6 = not na(t6) and (chgT6 != 0)
newF7 = not na(t7) and (chgT7 != 0)

// Outlook scores + components
outScore1 = f_state_score(c1, ef1, es1, r1)
outScore2 = f_state_score(c2, ef2, es2, r2)
outScore3 = f_state_score(c3, ef3, es3, r3)
outScore4 = f_state_score(c4, ef4, es4, r4)
outScore5 = f_state_score(c5, ef5, es5, r5)
outScore6 = f_state_score(c6, ef6, es6, r6)
outScore7 = f_state_score(c7, ef7, es7, r7)

[t1c, m1c, l1c] = f_state_tml(c1, ef1, es1, r1)
[t2c, m2c, l2c] = f_state_tml(c2, ef2, es2, r2)
[t3c, m3c, l3c] = f_state_tml(c3, ef3, es3, r3)
[t4c, m4c, l4c] = f_state_tml(c4, ef4, es4, r4)
[t5c, m5c, l5c] = f_state_tml(c5, ef5, es5, r5)
[t6c, m6c, l6c] = f_state_tml(c6, ef6, es6, r6)
[t7c, m7c, l7c] = f_state_tml(c7, ef7, es7, r7)

outSym(score) => score > 0.05 ? "â–²" : score < -0.05 ? "â–¼" : "âˆ’"
outCol(score) => score > 0.05 ? color.lime : score < -0.05 ? color.red : tblText

//====================
// Calibration storage â€” per horizon TF (Removed - moved to top)
//====================
// (Moved to top level state)

//====================
// Reset handling (rising edge) â€” per horizon F1..F7
//====================
var bool prevResetNow = false
doReset = resetNow and not prevResetNow
prevResetNow := resetNow

if doReset
    if resetWhich == "All"
        f_reset_eval_all()
    
    if resetWhich == "All" or resetWhich == "F1"
        f_reset_tf(tf1State)
    if resetWhich == "All" or resetWhich == "F2"
        f_reset_tf(tf2State)
    if resetWhich == "All" or resetWhich == "F3"
        f_reset_tf(tf3State)
    if resetWhich == "All" or resetWhich == "F4"
        f_reset_tf(tf4State)
    if resetWhich == "All" or resetWhich == "F5"
        f_reset_tf(tf5State)
    if resetWhich == "All" or resetWhich == "F6"
        f_reset_tf(tf6State)
    if resetWhich == "All" or resetWhich == "F7"
        f_reset_tf(tf7State)

//====================
// Calibration update (bar-close confirmed guard + new TF bar events)
//====================
doCal = enableForecast and barstate.isconfirmed
if doCal
    // F1
    [fc1, kb1, at1, ph1, tp1, sl1] = f_get_params(tfF1)
    f_process_tf(1, newF1, outScore1, c1, h1, l1, a1, vR1, ef1, es1, 
         tf1State,
         fc1, kb1, at1, ph1, tp1, sl1,
         alphaN, alpha1, kShrink, wState, wPullback, wRegime)

    // F2
    [fc2, kb2, at2, ph2, tp2, sl2] = f_get_params(tfF2)
    f_process_tf(2, newF2, outScore2, c2, h2, l2, a2, vR2, ef2, es2, 
         tf2State,
         fc2, kb2, at2, ph2, tp2, sl2,
         alphaN, alpha1, kShrink, wState, wPullback, wRegime)

    // F3
    [fc3, kb3, at3, ph3, tp3, sl3] = f_get_params(tfF3)
    f_process_tf(3, newF3, outScore3, c3, h3, l3, a3, vR3, ef3, es3, 
         tf3State,
         fc3, kb3, at3, ph3, tp3, sl3,
         alphaN, alpha1, kShrink, wState, wPullback, wRegime)

    // F4
    [fc4, kb4, at4, ph4, tp4, sl4] = f_get_params(tfF4)
    f_process_tf(4, newF4, outScore4, c4, h4, l4, a4, vR4, ef4, es4, 
         tf4State,
         fc4, kb4, at4, ph4, tp4, sl4,
         alphaN, alpha1, kShrink, wState, wPullback, wRegime)

    // F5
    [fc5, kb5, at5, ph5, tp5, sl5] = f_get_params(tfF5)
    f_process_tf(5, newF5, outScore5, c5, h5, l5, a5, vR5, ef5, es5, 
         tf5State,
         fc5, kb5, at5, ph5, tp5, sl5,
         alphaN, alpha1, kShrink, wState, wPullback, wRegime)

    // F6
    [fc6, kb6, at6, ph6, tp6, sl6] = f_get_params(tfF6)
    f_process_tf(6, newF6, outScore6, c6, h6, l6, a6, vR6, ef6, es6, 
         tf6State,
         fc6, kb6, at6, ph6, tp6, sl6,
         alphaN, alpha1, kShrink, wState, wPullback, wRegime)

    // F7
    [fc7, kb7, at7, ph7, tp7, sl7] = f_get_params(tfF7)
    f_process_tf(7, newF7, outScore7, c7, h7, l7, a7, vR7, ef7, es7, 
         tf7State,
         fc7, kb7, at7, ph7, tp7, sl7,
         alphaN, alpha1, kShrink, wState, wPullback, wRegime)

//====================
// Display values â€” N (Calibrated) per horizon
//====================
f_get_disp_prob(sA, c, h, l, a, vR, ef, es, wA, wB, wC, cnt, up, bins, alpha, shrink, platt) =>
    bias = ef > es ? 1 : -1
    sB = f_pullback_score(c, ef, es, bias)
    sC = vR >= VOL_THRESH_HIGH ? -1.0 : (vR <= VOL_THRESH_LOW ? 1.0 : 0.0)
    sEns = f_ensemble(sA, sB, sC, wA, wB, wC)
    b = f_bin2D(sEns, vR, bins, dim2Bins)
    [pRaw, nRaw] = f_cal_cur(cnt, up, b, alpha, shrink)
    aP = array.get(platt, 0)
    bP = array.get(platt, 1)
    pCal = f_platt_prob(pRaw, aP, bP)
    [pCal, nRaw]

[pN1, nN1] = f_get_disp_prob(outScore1, c1, h1, l1, a1, vR1, ef1, es1, wState, wPullback, wRegime, tf1State.cntN, tf1State.upN, predBinsN, alphaN, kShrink, tf1State.plattN)
[pN2, nN2] = f_get_disp_prob(outScore2, c2, h2, l2, a2, vR2, ef2, es2, wState, wPullback, wRegime, tf2State.cntN, tf2State.upN, predBinsN, alphaN, kShrink, tf2State.plattN)
[pN3, nN3] = f_get_disp_prob(outScore3, c3, h3, l3, a3, vR3, ef3, es3, wState, wPullback, wRegime, tf3State.cntN, tf3State.upN, predBinsN, alphaN, kShrink, tf3State.plattN)
[pN4, nN4] = f_get_disp_prob(outScore4, c4, h4, l4, a4, vR4, ef4, es4, wState, wPullback, wRegime, tf4State.cntN, tf4State.upN, predBinsN, alphaN, kShrink, tf4State.plattN)
[pN5, nN5] = f_get_disp_prob(outScore5, c5, h5, l5, a5, vR5, ef5, es5, wState, wPullback, wRegime, tf5State.cntN, tf5State.upN, predBinsN, alphaN, kShrink, tf5State.plattN)
[pN6, nN6] = f_get_disp_prob(outScore6, c6, h6, l6, a6, vR6, ef6, es6, wState, wPullback, wRegime, tf6State.cntN, tf6State.upN, predBinsN, alphaN, kShrink, tf6State.plattN)
[pN7, nN7] = f_get_disp_prob(outScore7, c7, h7, l7, a7, vR7, ef7, es7, wState, wPullback, wRegime, tf7State.cntN, tf7State.upN, predBinsN, alphaN, kShrink, tf7State.plattN)

[p11p, n11p] = f_get_disp_prob(outScore1, c1, h1, l1, a1, vR1, ef1, es1, wState, wPullback, wRegime, tf1State.cnt1, tf1State.up1, predBins1, alpha1, kShrink, tf1State.platt1)
[p12p, n12p] = f_get_disp_prob(outScore2, c2, h2, l2, a2, vR2, ef2, es2, wState, wPullback, wRegime, tf2State.cnt1, tf2State.up1, predBins1, alpha1, kShrink, tf2State.platt1)
[p13p, n13p] = f_get_disp_prob(outScore3, c3, h3, l3, a3, vR3, ef3, es3, wState, wPullback, wRegime, tf3State.cnt1, tf3State.up1, predBins1, alpha1, kShrink, tf3State.platt1)
[p14p, n14p] = f_get_disp_prob(outScore4, c4, h4, l4, a4, vR4, ef4, es4, wState, wPullback, wRegime, tf4State.cnt1, tf4State.up1, predBins1, alpha1, kShrink, tf4State.platt1)
[p15p, n15p] = f_get_disp_prob(outScore5, c5, h5, l5, a5, vR5, ef5, es5, wState, wPullback, wRegime, tf5State.cnt1, tf5State.up1, predBins1, alpha1, kShrink, tf5State.platt1)
[p16p, n16p] = f_get_disp_prob(outScore6, c6, h6, l6, a6, vR6, ef6, es6, wState, wPullback, wRegime, tf6State.cnt1, tf6State.up1, predBins1, alpha1, kShrink, tf6State.platt1)
[p17p, n17p] = f_get_disp_prob(outScore7, c7, h7, l7, a7, vR7, ef7, es7, wState, wPullback, wRegime, tf7State.cnt1, tf7State.up1, predBins1, alpha1, kShrink, tf7State.platt1)

// --- Total resolved samples per TF (across all bins)
// (These totals will usually be identical for (N) and (1) because both get updated from the same resolved events.)
totN1 = f_sum_int_array(tf1State.cntN)
totN2 = f_sum_int_array(tf2State.cntN)
totN3 = f_sum_int_array(tf3State.cntN)
totN4 = f_sum_int_array(tf4State.cntN)
totN5 = f_sum_int_array(tf5State.cntN)
totN6 = f_sum_int_array(tf6State.cntN)
totN7 = f_sum_int_array(tf7State.cntN)

tot11 = f_sum_int_array(tf1State.cnt1)
tot12 = f_sum_int_array(tf2State.cnt1)
tot13 = f_sum_int_array(tf3State.cnt1)
tot14 = f_sum_int_array(tf4State.cnt1)
tot15 = f_sum_int_array(tf5State.cnt1)
tot16 = f_sum_int_array(tf6State.cnt1)
tot17 = f_sum_int_array(tf7State.cnt1)

// calibration â€œenabled for displayâ€ if forecast enabled + we have any resolved samples in that TF
canF1N = enableForecast and (totN1 > 0)
canF2N = enableForecast and (totN2 > 0)
canF3N = enableForecast and (totN3 > 0)
canF4N = enableForecast and (totN4 > 0)
canF5N = enableForecast and (totN5 > 0)
canF6N = enableForecast and (totN6 > 0)
canF7N = enableForecast and (totN7 > 0)

canF11 = enableForecast and (tot11 > 0)
canF12 = enableForecast and (tot12 > 0)
canF13 = enableForecast and (tot13 > 0)
canF14 = enableForecast and (tot14 > 0)
canF15 = enableForecast and (tot15 > 0)
canF16 = enableForecast and (tot16 > 0)
canF17 = enableForecast and (tot17 > 0)

//====================
// Table helpers MUST be global (cannot be defined inside if-block)
//====================
var table gT = na
if na(gT)
    gT := table.new(position.middle_right, 5, 35, bgcolor=tblBg, frame_color=tblFrame, frame_width=1, border_color=tblFrame, border_width=1)

f_rowOut(tf, score, tC, mC, lC, rV, rRow) =>
    table.cell(gT, 0, rRow, f_tfLabel(tf), text_color=tblTfColor, bgcolor=tblCell, text_size=size.tiny)
    table.cell(gT, 1, rRow, outSym(score),  text_color=outCol(score), bgcolor=tblCell, text_size=size.tiny)
    table.cell(gT, 2, rRow, str.tostring(score, "#.00"), text_color=tblText, bgcolor=tblCell, text_size=size.tiny)
    table.cell(gT, 3, rRow, str.tostring(tC) + "/" + str.tostring(mC) + "/" + str.tostring(lC), text_color=tblTextDim, bgcolor=tblCell, text_size=size.tiny)
    table.cell(gT, 4, rRow, str.tostring(rV, "#.0"), text_color=tblText, bgcolor=tblCell, text_size=size.tiny)

f_rowFc(tf, pN, nBinN, totN_, canN_, p1, nBin1, tot1_, can1_, rRow) =>
    table.cell(gT, 0, rRow, f_tfLabel(tf), text_color=tblTfColor, bgcolor=tblCell, text_size=size.tiny)

    // Chance(N)
    txtChanceN = f_chance_text(tf, pN, nBinN, totN_, canN_)
    colChanceN = f_predColorP(pN, nBinN, canN_, tblText)
    table.cell(gT, 1, rRow, txtChanceN, text_color=colChanceN, bgcolor=tblCell, text_size=size.tiny)

    // Data(N) = bin/total + label + range
    txtDataN = f_data_text(pN, nBinN, totN_, canN_)
    colDataN = f_rel_color(pN, nBinN, totN_, canN_)
    table.cell(gT, 2, rRow, txtDataN, text_color=colDataN, bgcolor=tblCell, text_size=size.tiny)

    // Chance(1)
    txtChance1 = f_chance_text(tf, p1, nBin1, tot1_, can1_)
    colChance1 = f_predColorP(p1, nBin1, can1_, tblText)
    table.cell(gT, 3, rRow, txtChance1, text_color=colChance1, bgcolor=tblCell, text_size=size.tiny)

    // Data(1)
    txtData1 = f_data_text(p1, nBin1, tot1_, can1_)
    colData1 = f_rel_color(p1, nBin1, tot1_, can1_)
    table.cell(gT, 4, rRow, txtData1, text_color=colData1, bgcolor=tblCell, text_size=size.tiny)

f_fmtBrier(stats) =>
    s = array.get(stats, 0)
    c = array.get(stats, 1)
    val = c > 0 ? s / c : na
    txt = na(val) ? "â€”" : str.tostring(val, "#.###")
    col = na(val) ? tblTextDim : val < 0.20 ? color.green : val < 0.25 ? color.lime : val < 0.30 ? color.yellow : color.red
    [txt, col]

f_fmtCnt(stats) =>
    c = array.get(stats, 1)
    [str.tostring(c, "#"), c < 10 ? tblTextDim : tblText]

f_rowRel(tf, statsN, stats1, rRow) =>
    table.cell(gT, 0, rRow, f_tfLabel(tf), text_color=tblTfColor, bgcolor=tblCell, text_size=size.tiny)
    
    [tN, cN] = f_fmtBrier(statsN)
    table.cell(gT, 1, rRow, tN, text_color=cN, bgcolor=tblCell, text_size=size.tiny)
    
    [tB1, cB1] = f_fmtBrier(stats1)
    table.cell(gT, 2, rRow, tB1, text_color=cB1, bgcolor=tblCell, text_size=size.tiny)
    
    [tcN, ccN] = f_fmtCnt(statsN)
    table.cell(gT, 3, rRow, tcN, text_color=ccN, bgcolor=tblCell, text_size=size.tiny)
    
    [tc1, cc1] = f_fmtCnt(stats1)
    table.cell(gT, 4, rRow, tc1, text_color=cc1, bgcolor=tblCell, text_size=size.tiny)

// --- Evaluation Helpers
f_eval_get(hid) =>
    float bAvg = na, float lAvg = na
    float ece = na, float mErr = na
    float wS = na, float wL = na
    float drift = na, float nSc = na
    
    TfState st = na
    if hid == 1
        st := tf1State
    else if hid == 2
        st := tf2State
    else if hid == 3
        st := tf3State
    else if hid == 4
        st := tf4State
    else if hid == 5
        st := tf5State
    else if hid == 6
        st := tf6State
    else 
        st := tf7State

    if not na(st)
        // Switch to get arrays based on head (N or 1)
        if evalWhichHead == "N"
            [b0,b1,e0,e1,w0,w1,d0,n0] = f_eval_stats_one(st.evBrierN, st.evSumBrierN, st.evLogN, st.evSumLogN, st.evYS_N, st.evSumYS_N, st.evYL_N, st.evSumYL_N, st.evCalCntN, st.evCalSumPN, st.evCalSumYN)
            bAvg := b0, lAvg := b1, ece := e0, mErr := e1, wS := w0, wL := w1, drift := d0, nSc := n0
        else
            [b0,b1,e0,e1,w0,w1,d0,n0] = f_eval_stats_one(st.evBrier1, st.evSumBrier1, st.evLog1, st.evSumLog1, st.evYS_1, st.evSumYS_1, st.evYL_1, st.evSumYL_1, st.evCalCnt1, st.evCalSumP1, st.evCalSumY1)
            bAvg := b0, lAvg := b1, ece := e0, mErr := e1, wS := w0, wL := w1, drift := d0, nSc := n0
        
    [bAvg, lAvg, ece, mErr, wS, wL, drift, nSc]

f_rowEval(tf, hid, rRow) =>
    [bAvg, lAvg, ece, mErr, wS, wL, drift, nSc] = f_eval_get(hid)
    
    // Label
    table.cell(gT, 0, rRow, f_tfLabel(tf), text_color=tblTfColor, bgcolor=tblCell, text_size=size.tiny)

    if na(nSc) or nSc == 0
        table.cell(gT, 1, rRow, "â€”", text_color=tblTextDim, bgcolor=tblCell, text_size=size.tiny)
        table.cell(gT, 2, rRow, "â€”", text_color=tblTextDim, bgcolor=tblCell, text_size=size.tiny)
        table.cell(gT, 3, rRow, "â€”", text_color=tblTextDim, bgcolor=tblCell, text_size=size.tiny)
        table.cell(gT, 4, rRow, "0",   text_color=tblTextDim, bgcolor=tblCell, text_size=size.tiny)
    else
        // LogLoss
        // ideal ~ 0.693 for random 50/50. Good < 0.65 ?? 
        // We'll just color based on existence
        llTxt = str.tostring(lAvg, "#.000")
        table.cell(gT, 1, rRow, llTxt, text_color=tblText, bgcolor=tblCell, text_size=size.tiny)

        // ECE / Max
        eceT = str.tostring(ece * 100, "#.0")
        maxT = str.tostring(mErr * 100, "#.0")
        comb = eceT + "/" + maxT
        // Color ECE: < 5% is great, <10% ok
        cEce = ece < 0.05 ? color.lime : ece < 0.10 ? color.yellow : color.red
        table.cell(gT, 2, rRow, comb, text_color=cEce, bgcolor=tblCell, text_size=size.tiny)

        // Drift
        drT = f_ppSigned(drift)
        // positive drift = Short yield > Long yield? 
        // Actually wS - wL. If > 0 => Short doing better.
        // We assume neutral is 0.
        table.cell(gT, 3, rRow, drT, text_color=tblText, bgcolor=tblCell, text_size=size.tiny)
        
        // Count
        table.cell(gT, 4, rRow, str.tostring(nSc, "#"), text_color=tblTextDim, bgcolor=tblCell, text_size=size.tiny)


//====================
// Table (5 columns) â€” rendered on confirmed bars (stable)
//====================
mtfStr  = useMtfConfirm ? (setUse + " " + str.tostring(mtfScore, format.mintick)) : "OFF"
posStr  = pos == 1 ? "LONG" : pos == -1 ? "SHORT" : "FLAT"
confStr = str.tostring(confidence * 100.0, "#.0") + "%"
volStr  = f_fmtVol(volume)

strengthVal = rsi7
strengthStr = str.tostring(strengthVal, "#.0")
c_strength  = strengthVal <= 45 ? color.red : strengthVal > 70 ? color.green : color.yellow
c_conf = f_confColor(confidence)
c_vol  = volAvail ? color.lime : tblText

targetDesc = "Multi-Profile (See Settings). Fast: " + fcTargetF + ", Mid: " + fcTargetM + ", Slow: " + fcTargetS

if showTable and barstate.isconfirmed
    table.clear(gT, 0, 0, 4, 33)

    // Status rows
    table.cell(gT, 0, 0, "Confidence", text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 1, 0, confStr,       text_color=c_conf,    bgcolor=tblCell,   text_size=size.tiny)
    table.cell(gT, 2, 0, "", text_color=tblText, bgcolor=tblCell, text_size=size.tiny)
    table.cell(gT, 3, 0, "", text_color=tblText, bgcolor=tblCell, text_size=size.tiny)
    table.cell(gT, 4, 0, "", text_color=tblText, bgcolor=tblCell, text_size=size.tiny)

    table.cell(gT, 0, 1, "MinTrust", text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 1, 1, str.tostring(minTrust, format.mintick), text_color=tblText, bgcolor=tblCell, text_size=size.tiny)

    table.cell(gT, 0, 2, "Volume", text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 1, 2, volStr,   text_color=c_vol,      bgcolor=tblCell,   text_size=size.tiny)

    table.cell(gT, 0, 3, "Strength", text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 1, 3, strengthStr, text_color=c_strength, bgcolor=tblCell, text_size=size.tiny)

    table.cell(gT, 0, 4, "MTF", text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 1, 4, mtfStr, text_color=tblText, bgcolor=tblCell, text_size=size.tiny)

    table.cell(gT, 0, 5, "Pos", text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 1, 5, posStr, text_color=tblText, bgcolor=tblCell, text_size=size.tiny)

    table.cell(gT, 0, 6, "LastSig", text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 1, 6, lastSig, text_color=tblText, bgcolor=tblCell, text_size=size.tiny)

    table.cell(gT, 0, 7, "Time", text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 1, 7, str.format_time(time, "yyyy-MM-dd HH:mm"), text_color=tblText, bgcolor=tblCell, text_size=size.tiny)

    // Outlook header
    table.cell(gT, 0, 8, "Outlook", text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 1, 8, "Bias",    text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 2, 8, "Score",   text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 3, 8, "T/M/L",   text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 4, 8, "RSI",     text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)

    f_rowOut(tfF1, outScore1, t1c, m1c, l1c, r1,  9)
    f_rowOut(tfF2, outScore2, t2c, m2c, l2c, r2, 10)
    f_rowOut(tfF3, outScore3, t3c, m3c, l3c, r3, 11)
    f_rowOut(tfF4, outScore4, t4c, m4c, l4c, r4, 12)
    f_rowOut(tfF5, outScore5, t5c, m5c, l5c, r5, 13)
    f_rowOut(tfF6, outScore6, t6c, m6c, l6c, r6, 14)
    f_rowOut(tfF7, outScore7, t7c, m7c, l7c, r7, 15)

    // Forecast header
    table.cell(gT, 0, 16, "Forecast",   text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 1, 16, "Chance(N)",  text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 2, 16, "Data(N)",    text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 3, 16, "Chance(1)",  text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 4, 16, "Data(1)",    text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)

    f_rowFc(tfF1, pN1, nN1, totN1, canF1N, p11p, n11p, tot11, canF11, 17)
    f_rowFc(tfF2, pN2, nN2, totN2, canF2N, p12p, n12p, tot12, canF12, 18)
    f_rowFc(tfF3, pN3, nN3, totN3, canF3N, p13p, n13p, tot13, canF13, 19)
    f_rowFc(tfF4, pN4, nN4, totN4, canF4N, p14p, n14p, tot14, canF14, 20)
    f_rowFc(tfF5, pN5, nN5, totN5, canF5N, p15p, n15p, tot15, canF15, 21)
    f_rowFc(tfF6, pN6, nN6, totN6, canF6N, p16p, n16p, tot16, canF16, 22)
    f_rowFc(tfF7, pN7, nN7, totN7, canF7N, p17p, n17p, tot17, canF17, 23)

    // Evaluation header & rows
    table.cell(gT, 0, 24, "Evaluation",   text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 1, 24, "LogLoss",      text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 2, 24, "ECE/Max",      text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 3, 24, "Drift(S-L)",   text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 4, 24, "#Obs",         text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)

    f_rowEval(tfF1, 1, 25)
    f_rowEval(tfF2, 2, 26)
    f_rowEval(tfF3, 3, 27)
    f_rowEval(tfF4, 4, 28)
    f_rowEval(tfF5, 5, 29)
    f_rowEval(tfF6, 6, 30)
    f_rowEval(tfF7, 7, 31)

    // Footer
    table.cell(gT, 0, 32, "Target", text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 1, 32, targetDesc, text_color=tblText, bgcolor=tblCell, text_size=size.tiny)
    table.merge_cells(gT, 1, 32, 4, 32)

    table.cell(gT, 0, 33, "Note", text_color=tblTextDim, bgcolor=tblHeader, text_size=size.tiny)
    table.cell(gT, 1, 33,
     "Forecast: Shrinkage k=5.0 active. Accuracy: Brier Score (0-1). <0.25=Skill.",
     text_color=tblTextDim, bgcolor=tblCell, text_size=size.tiny)
    table.merge_cells(gT, 1, 33, 4, 33)

//====================
// Calibration Diagnostics Panel (Debug)
//====================
var table diagTbl = na
if showDiagPanel and na(diagTbl)
    diagTbl := table.new(position.top_right, 2, 14, bgcolor=color.new(color.black, 85), frame_color=color.gray, frame_width=1, border_color=color.gray, border_width=1)

// Helper to get selected TfState
f_get_diag_state() =>
    diagHorizon == "F1" ? tf1State : diagHorizon == "F2" ? tf2State : diagHorizon == "F3" ? tf3State : diagHorizon == "F4" ? tf4State : diagHorizon == "F5" ? tf5State : diagHorizon == "F6" ? tf6State : tf7State

if showDiagPanel and barstate.islast
    st = f_get_diag_state()
    
    // Select model arrays
    cntArr = diagModel == "N" ? st.cntN : st.cnt1
    upArr  = diagModel == "N" ? st.upN  : st.up1
    plattArr = diagModel == "N" ? st.plattN : st.platt1
    brierStats = diagModel == "N" ? st.brierStatsN : st.brierStats1
    llStats = diagModel == "N" ? st.llStatsN : st.llStats1
    
    // Platt params
    plattA = array.get(plattArr, 0)
    plattB = array.get(plattArr, 1)
    
    // Brier/LogLoss
    brierSum = array.get(brierStats, 0)
    brierCnt = array.get(brierStats, 1)
    brierAvg = brierCnt > 0 ? brierSum / brierCnt : na
    
    llSum = array.get(llStats, 0)
    llCnt = array.get(llStats, 1)
    llAvg = llCnt > 0 ? llSum / llCnt : na
    
    // Bin samples (total and per-bin distribution)
    totalSamples = array.sum(cntArr)
    numBins = array.size(cntArr)
    
    // Bin distribution (min/max/avg samples per bin)
    minBin = numBins > 0 ? array.min(cntArr) : 0
    maxBin = numBins > 0 ? array.max(cntArr) : 0
    avgBin = numBins > 0 ? totalSamples / numBins : 0
    
    // Win rate (overall calibrated base rate)
    totalUp = array.sum(upArr)
    baseRate = totalSamples > 0 ? totalUp * 100.0 / totalSamples : 50.0
    
    // Convergence check: Is Platt A stable (should be near 1.0 if well-calibrated)?
    plattStable = (plattA >= 0.7 and plattA <= 1.5) and (plattB >= -0.5 and plattB <= 0.5)
    convStatus = plattStable ? "âœ… Converged" : (plattA < 0.3 or plattA > 3.0) ? "âš ï¸ Unstable" : "ðŸ”„ Adjusting"
    convColor = plattStable ? color.lime : (plattA < 0.3 or plattA > 3.0) ? color.red : color.yellow
    
    // Quality grade
    qualityGrade = na(brierAvg) ? "â€”" : brierAvg < 0.18 ? "A (Excellent)" : brierAvg < 0.22 ? "B (Good)" : brierAvg < 0.25 ? "C (Baseline)" : brierAvg < 0.30 ? "D (Poor)" : "F (No Skill)"
    qualityColor = na(brierAvg) ? color.gray : brierAvg < 0.18 ? color.lime : brierAvg < 0.22 ? color.green : brierAvg < 0.25 ? color.yellow : brierAvg < 0.30 ? color.orange : color.red
    
    // Row 0: Header
    table.cell(diagTbl, 0, 0, "ðŸ”§ Calibration Diagnostics", text_color=color.white, bgcolor=color.new(color.blue, 70), text_size=size.small)
    table.cell(diagTbl, 1, 0, diagHorizon + " / " + diagModel, text_color=color.aqua, bgcolor=color.new(color.blue, 70), text_size=size.small)
    
    // Row 1: Platt A
    table.cell(diagTbl, 0, 1, "Platt A (slope)", text_color=color.gray, text_size=size.tiny)
    table.cell(diagTbl, 1, 1, str.tostring(plattA, "#.###"), text_color=color.white, text_size=size.tiny)
    
    // Row 2: Platt B
    table.cell(diagTbl, 0, 2, "Platt B (intercept)", text_color=color.gray, text_size=size.tiny)
    table.cell(diagTbl, 1, 2, str.tostring(plattB, "#.###"), text_color=color.white, text_size=size.tiny)
    
    // Row 3: Convergence status
    table.cell(diagTbl, 0, 3, "SGD Status", text_color=color.gray, text_size=size.tiny)
    table.cell(diagTbl, 1, 3, convStatus, text_color=convColor, text_size=size.tiny)
    
    // Row 4: Separator
    table.cell(diagTbl, 0, 4, "â”€â”€â”€â”€â”€â”€â”€â”€â”€", text_color=color.gray, text_size=size.tiny)
    table.cell(diagTbl, 1, 4, "â”€â”€â”€â”€â”€â”€â”€â”€â”€", text_color=color.gray, text_size=size.tiny)
    
    // Row 5: Brier Score
    table.cell(diagTbl, 0, 5, "Brier Score", text_color=color.gray, text_size=size.tiny)
    table.cell(diagTbl, 1, 5, na(brierAvg) ? "â€”" : str.tostring(brierAvg, "#.####"), text_color=na(brierAvg) ? color.gray : brierAvg < 0.25 ? color.lime : color.red, text_size=size.tiny)
    
    // Row 6: LogLoss
    table.cell(diagTbl, 0, 6, "LogLoss", text_color=color.gray, text_size=size.tiny)
    table.cell(diagTbl, 1, 6, na(llAvg) ? "â€”" : str.tostring(llAvg, "#.####"), text_color=na(llAvg) ? color.gray : llAvg < 0.65 ? color.lime : color.red, text_size=size.tiny)
    
    // Row 7: Quality Grade
    table.cell(diagTbl, 0, 7, "Quality Grade", text_color=color.gray, text_size=size.tiny)
    table.cell(diagTbl, 1, 7, qualityGrade, text_color=qualityColor, text_size=size.tiny)
    
    // Row 8: Separator
    table.cell(diagTbl, 0, 8, "â”€â”€â”€â”€â”€â”€â”€â”€â”€", text_color=color.gray, text_size=size.tiny)
    table.cell(diagTbl, 1, 8, "â”€â”€â”€â”€â”€â”€â”€â”€â”€", text_color=color.gray, text_size=size.tiny)
    
    // Row 9: Total samples
    table.cell(diagTbl, 0, 9, "Total Samples", text_color=color.gray, text_size=size.tiny)
    table.cell(diagTbl, 1, 9, str.tostring(totalSamples), text_color=totalSamples >= calMinSamples * numBins ? color.lime : color.yellow, text_size=size.tiny)
    
    // Row 10: Bin distribution
    table.cell(diagTbl, 0, 10, "Bin Min/Avg/Max", text_color=color.gray, text_size=size.tiny)
    table.cell(diagTbl, 1, 10, str.tostring(minBin) + "/" + str.tostring(avgBin, "#") + "/" + str.tostring(maxBin), text_color=color.white, text_size=size.tiny)
    
    // Row 11: Warmup progress
    warmupPct = math.min(100, totalSamples * 100.0 / (calMinSamples * numBins))
    table.cell(diagTbl, 0, 11, "Warmup Progress", text_color=color.gray, text_size=size.tiny)
    table.cell(diagTbl, 1, 11, str.tostring(warmupPct, "#.0") + "%", text_color=warmupPct >= 100 ? color.lime : warmupPct >= 50 ? color.yellow : color.red, text_size=size.tiny)
    
    // Row 12: Base Rate
    table.cell(diagTbl, 0, 12, "Base Rate (Up%)", text_color=color.gray, text_size=size.tiny)
    table.cell(diagTbl, 1, 12, str.tostring(baseRate, "#.1") + "%", text_color=math.abs(baseRate - 50) > 15 ? color.orange : color.white, text_size=size.tiny)
    
    // Row 13: Observations count
    table.cell(diagTbl, 0, 13, "Resolutions", text_color=color.gray, text_size=size.tiny)
    table.cell(diagTbl, 1, 13, str.tostring(int(brierCnt)), text_color=color.white, text_size=size.tiny)

//====================
// UT Bot Logic (Overlay, V4 Port)
//====================
utSrc = utUseHA ? request.security(ticker.heikinashi(syminfo.tickerid), timeframe.period, close, lookahead = barmerge.lookahead_off) : close
utXATR = ta.atr(utAtrPeriod)
utNLoss = utKey * utXATR

var float utXATRTrailingStop = 0.0
// Logic replication
utPrevStop = nz(utXATRTrailingStop[1], 0)
utSrc1 = utSrc[1]

if utSrc > utPrevStop and utSrc1 > utPrevStop
    utXATRTrailingStop := math.max(utPrevStop, utSrc - utNLoss)
else if utSrc < utPrevStop and utSrc1 < utPrevStop
    utXATRTrailingStop := math.min(utPrevStop, utSrc + utNLoss)
else if utSrc > utPrevStop
    utXATRTrailingStop := utSrc - utNLoss
else 
    utXATRTrailingStop := utSrc + utNLoss

var int utPos = 0
if utSrc1 < utPrevStop and utSrc > utPrevStop
    utPos := 1
else if utSrc1 > utPrevStop and utSrc < utPrevStop
    utPos := -1
else
    utPos := nz(utPos[1], 0)

utEma = ta.ema(utSrc, 1)
utAbove = ta.crossover(utEma, utXATRTrailingStop)
utBelow = ta.crossover(utXATRTrailingStop, utEma)

utBuy  = utSrc > utXATRTrailingStop and utAbove
utSell = utSrc < utXATRTrailingStop and utBelow

utBarBuy  = utSrc > utXATRTrailingStop
utBarSell = utSrc < utXATRTrailingStop

plotshape(utShow and utBuy,  title = "UT Buy",  text = 'UT Buy',  style = shape.labelup,   location = location.belowbar, color= color.green, textcolor = color.white, size = size.tiny)
plotshape(utShow and utSell, title = "UT Sell", text = 'UT Sell', style = shape.labeldown, location = location.abovebar, color= color.red,   textcolor = color.white, size = size.tiny)

barcolor(utShow and utBarBuy ? color.green : utShow and utBarSell ? color.red : na)

alertcondition(utBuy,  "UT Bot Long",  "UT Bot Long")
alertcondition(utSell, "UT Bot Short", "UT Bot Short")

//====================
// Alerts (bar close)
//====================
alertcondition(buySignal,   title="BUY (bar close)",   message="BUY {{ticker}} @ {{close}}")
alertcondition(exitSignal,  title="EXIT (bar close)",  message="EXIT {{ticker}} @ {{close}}")
alertcondition(shortSignal, title="SHORT (bar close)", message="SHORT {{ticker}} @ {{close}}")
alertcondition(coverSignal, title="COVER (bar close)", message="COVER {{ticker}} @ {{close}}")
